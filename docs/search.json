[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estadística para el Análisis Político 1",
    "section": "",
    "text": "Sobre el curso",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n\n\nKnuth, Donald E. 1984. «Literate Programming». Comput. J. 27 (2): 97-111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "index.html#bienvenido",
    "href": "index.html#bienvenido",
    "title": "Estadística para el Análisis Político 1",
    "section": "Bienvenido",
    "text": "Bienvenido",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "index.html#sílabo",
    "href": "index.html#sílabo",
    "title": "Estadística para el Análisis Político 1",
    "section": "Sílabo",
    "text": "Sílabo",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "s1_intro.html",
    "href": "s1_intro.html",
    "title": "1  Fundamentos de programación con R",
    "section": "",
    "text": "1.1 Objetivos de la sesión",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentos de programación con R</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html",
    "href": "s2_descriptivo.html",
    "title": "2  Manipulación de tablas",
    "section": "",
    "text": "2.1 Objetivos de la sesión",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s3_visualizacion.html",
    "href": "s3_visualizacion.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#estadística-los-fundamentos",
    "href": "s1_intro.html#estadística-los-fundamentos",
    "title": "1  Introducción",
    "section": "1.2 Estadística: los fundamentos",
    "text": "1.2 Estadística: los fundamentos",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "index.html#bienvenida",
    "href": "index.html#bienvenida",
    "title": "Estadística para el Análisis Político 1",
    "section": "Bienvenida",
    "text": "Bienvenida\nHola! Bienvenid@ al curso de Estadística para el Análisis Político 1 de la especialidad de Ciencia Política y Gobierno de la Pontificia Universidad Católica del Perú.\nEn esta página podrás encontrar toda la información referida al curso tal como: presentaciones (ppt), código, texto explicativo y material audiovisual adicional..",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "index.html#ia-generativa",
    "href": "index.html#ia-generativa",
    "title": "Estadística para el Análisis Político 1",
    "section": "IA generativa",
    "text": "IA generativa\nPermitimos y promovemos activamente el uso de inteligencia artificial generativa, como ChatGPT, Gemini, y otras plataformas similares, como soporte para la creación y sofisticación del código en R.\nCreemos firmemente que estas herramientas pueden ser aliados significativos para profundizar en la comprensión de conceptos complejos, mejorar las habilidades de programación y fomentar la innovación y creatividad en nuestros proyectos y tareas.\nLa integración de la inteligencia artificial en nuestro proceso de aprendizaje ofrece una oportunidad única para experimentar con nuevas formas de resolver problemas, optimizar procesos y generar ideas que puedan llevar nuestra capacidad analítica y técnica a nuevos niveles.\nSin embargo, es importante destacar que, mientras fomentamos el uso de estas herramientas tecnológicas avanzadas para la exploración y el aprendizaje durante el curso, no se permitirá su uso en las evaluaciones.",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "s1_intro.html#fundamentos-de-r",
    "href": "s1_intro.html#fundamentos-de-r",
    "title": "1  Introducción",
    "section": "1.2 Fundamentos de R",
    "text": "1.2 Fundamentos de R\n\n1.2.1 ¿Por qué R?\nR es un lenguaje de programación y un entorno de software libre orientado principalmente al análisis estadístico y la representación gráfica de datos. Desde su creación en 1993 por Ross Ihaka y Robert Gentleman en la Universidad de Auckland, R ha evolucionado para convertirse en una de las herramientas más populares y poderosas en el campo de la estadística y la ciencia de datos.\nAprender estadística con R tiene varias ventajas:\n\n\n\n\n\n\n\nVentaja\nDetalle\n\n\n\n\nFlexibilidad y Personalización\nR ofrece un amplio rango de análisis y permite la personalización y automatización según las necesidades del usuario.\n\n\nAmplio Repositorio de Paquetes\nLa comunidad de R ha desarrollado miles de paquetes, permitiendo fácil acceso a técnicas estadísticas avanzadas.\n\n\nReproducibilidad\nCon R, se pueden crear análisis que otros investigadores pueden verificar y replicar fácilmente.\n\n\nRepresentación Gráfica\nR destaca en la producción de gráficos de alta calidad, esenciales para la visualización de datos.\n\n\nComunidad Activa\nLa activa comunidad de R proporciona numerosos recursos, tutoriales y foros para el aprendizaje y resolución de dudas.\n\n\n\n\n\n1.2.2 POO\nR es un lenguaje de programación que adopta el paradigma de la “programación orientada a objetos”. Esto significa que, en R, todo se considera un “objeto”, ya sea un conjunto de datos, una función o un modelo. Cada objeto tiene atributos y comportamientos asociados que determinan cómo se puede interactuar con él. Esta estructura permite a los usuarios de R organizar y manipular datos de manera coherente y sistemática. Al entender que todo en R es un objeto, se puede abordar el análisis estadístico con una visión más estructurada, lo que facilita la comprensión y aplicación de técnicas y métodos avanzados en el futuro.\nImagina que cada objeto en R es como un coche. Los “atributos” de ese coche pueden incluir su color, marca, modelo, y año de fabricación. Estos atributos describen las características específicas del coche. Ahora, piensa en los “comportamientos asociados” como las acciones que puedes realizar con ese coche: encenderlo, acelerar, frenar o encender las luces. Del mismo modo, en R, un objeto, como un conjunto de datos, podría tener atributos que describan su tamaño, tipo y estructura. Y los comportamientos asociados de ese conjunto de datos podrían incluir operaciones como filtrar, ordenar o aplicar una función estadística.\nPor ejemplo, si tienes un objeto en R que es un dataframe (un tipo de estructura de datos tabular), sus “atributos” podrían incluir el número de filas y columnas, los nombres de las columnas y el tipo de datos en cada columna. Los “comportamientos asociados” de ese dataframe podrían ser operaciones como añadir o eliminar una columna, filtrar por ciertos valores o calcular estadísticas sobre una columna específica. Al comprender los atributos y comportamientos de los objetos en R, puedes manipularlos y analizarlos de manera efectiva y eficiente, al igual que un conductor experto sabe cómo manejar y cuidar su coche.\n\n\n1.2.3 Los objetos\nVamos a examinar la clase de algunos de los elementos más básicos en R: los números, los caracteres y los elementos lógicos.\n\nclass(1.5)\n\n[1] \"numeric\"\n\n# Para escribir valores character siempre entre comillas\nclass(\"rojo\") \n\n[1] \"character\"\n\n# Para escribir valores booleanos siempre usar mayúscula.\nclass(TRUE) \n\n[1] \"logical\"\n\n\nEn R, los datos pueden ser coercionados, es decir, forzados, para transformarlos de un tipo a otro.\n\nas.numeric(\"5\")\n\n[1] 5\n\nas.integer(5.1)\n\n[1] 5\n\nas.character(5)\n\n[1] \"5\"\n\n\nPodemos asignarles etiquetas (nombres) a esos elementos.\n\nx &lt;- 5.5\nclass(x)\n\n[1] \"numeric\"\n\ny &lt;- \"perro\"\nclass(y)\n\n[1] \"character\"\n\nz &lt;- TRUE\nclass(z)\n\n[1] \"logical\"\n\n\nConsiderar que también se puede usar el signo “=”. Sin embargo, tiene algunas diferencias en cuanto a su uso en el programa.\nPor ejemplo, uno puede escribir esta sentencia X &lt;-5+5 y 5+5-&gt;X.\nSin embargo, el sistema no acepta lo siguiente: 5+5 = X\n\n\n1.2.4 Los vectores\n\nUn vector es una colección de uno o más datos del mismo tipo.\nTipo. Un vector tiene el mismo tipo que los datos que contiene. Si tenemos un vector que contiene datos de tipo numérico, el vector será también de tipo numérico. Los vectores son atómicos, pues sólo pueden contener datos de un sólo tipo, no es posible mezclar datos de tipos diferentes dentro de ellos.\nLargo. Es el número de elementos que contiene un vector. El largo es la única dimensión que tiene esta estructura de datos.\nNO TIENE DIMENSIÓN (dim)\n\nEjemplo: Vamos a crear tres vectores: uno numérico, uno de caracter y uno lógico. Podemos utilizar la función length() para medir el largo de estos (cuántos elementos contiene).\n\nvector_numerico &lt;- c(1, 2, 3, 4, 5)\nlength(vector_numerico)\n\n[1] 5\n\n\n\nvector_caracter &lt;- c(\"arbol\", \"casa\", \"persona\")\nlength(vector_caracter)\n\n[1] 3\n\n\n\nvector_logico&lt;- c(TRUE, TRUE, FALSE, FALSE, TRUE)\nlength(vector_logico)\n\n[1] 5\n\n\nTambién podemos utilizar la función class() para corroborar que cada vector tiene la misma clase de los elementos que contiene.\n\nclass(vector_numerico)\n\n[1] \"numeric\"\n\nclass(vector_caracter)\n\n[1] \"character\"\n\nclass(vector_logico)\n\n[1] \"logical\"\n\n\nTener en cuenta que los vectores también pueden tener valores perdidos (NA).\n\nvector_con_NA &lt;- c(1,2,3,NA,5)  \nlength(vector_con_NA)\n\n[1] 5\n\nclass(vector_con_NA)\n\n[1] \"numeric\"\n\n\n\n\n1.2.5 Los factores\nUn factor es un tipo específico de vector en R. Puede ser descrito como un dato numérico representado por una etiqueta.\nSupongamos que tenemos un conjunto de datos que representan el género de personas encuestadas por teléfono, pero estos se encuentran capturados con los números 1 y 2.\n\ngenero &lt;- c(1,1,1,2,2,1,2)\n\nEl número 1 corresponde a Mujer y el 2 a Hombre. A diferencia del carácter, el factor tiene NIVELES (levels).\nPodemos crear un vector de tipo factor con la función factor().\n\ngenero_en_factor=factor(genero, \n       levels= 1:2,\n       labels=c(\"Mujer\", \"Hombre\"))\ngenero_en_factor\n\n[1] Mujer  Mujer  Mujer  Hombre Hombre Mujer  Hombre\nLevels: Mujer Hombre\n\n\nEn la práctica, muchas veces vamos a ver las variables de tipo factor en nuestro análisis. Por ello, debes ser muy cuidadoso en la preparación previa que debes realizar a la base de datos antes de aplicar las funciones.\nAsimismo, un factor puede estar ordenado o no ordenado. Esto nos sirve, por ejemplo, para crear variables de tipo ordinal. Podemos indicarlo ello, con el argumento ordered=.\nVeamos:\n\nconfianza=c(1, 1, 3, 2)\nconfianza_en_factor=factor(confianza, \n       levels= 1:3,\n       labels=c(\"Bajo\", \"Medio\", \"Alto\"), \n       ordered = TRUE)\nconfianza_en_factor\n\n[1] Bajo  Bajo  Alto  Medio\nLevels: Bajo &lt; Medio &lt; Alto\n\n\nVemos que nos indica los niveles, pero en este caso están ordenados de menor a mayor.\n\n\n1.2.6 Data frames\nLos data frames son estructuras de datos de dos dimensiones (rectangulares) que pueden contener datos de diferentes tipos, por lo tanto, son heterogéneas. Compuesto por vectores.\nEstructura más usada para ciencia de datos.\nMientras que en una matriz todas las celdas deben contener datos del mismo tipo, los renglones de un data frame admiten datos de distintos tipos, pero sus columnas conservan la restricción de contener datos de un sólo tipo.\nEn términos generales, los renglones en un data frame representan casos, individuos u observaciones, mientras que las columnas representan atributos, rasgos o variables.\n\nmi_df &lt;- data.frame(\n  \"variable1\" = 1:3, \n  \"variable2\" = c(1.2, 3.4, 4.5),\n  \"variable3\" = as.character(c(\"a\", \"b\", \"c\")),\n  \"variable4\" = as.factor(c(\"1\", \"2\", \"3\"))\n  ) #Para crear un DT los vectores de insumo deben ser del mismo largo\nmi_df\n\n  variable1 variable2 variable3 variable4\n1         1       1.2         a         1\n2         2       3.4         b         2\n3         3       4.5         c         3\n\nstr(mi_df)\n\n'data.frame':   3 obs. of  4 variables:\n $ variable1: int  1 2 3\n $ variable2: num  1.2 3.4 4.5\n $ variable3: chr  \"a\" \"b\" \"c\"\n $ variable4: Factor w/ 3 levels \"1\",\"2\",\"3\": 1 2 3\n\n\nPropiedades\nUn data.frame tiene:\n\nDimensión: un número de filas y un número de columnas.\n\n\ndim(mi_df) #FILAS Y COLUMNAS\n\n[1] 3 4\n\n\n\nLargo: número de casos\n\n\nlength(mi_df)\n\n[1] 4\n\n\n\nNombre de columnas: Podemos consultar el nombre de las columnas (variables) con la función names().\n\n\nnames(mi_df) \n\n[1] \"variable1\" \"variable2\" \"variable3\" \"variable4\"\n\n\n\n\n1.2.7 Índices\n\nUsar índices para obtener subconjuntos es el procedimiento más universal en R, pues funciona para todas las estructuras de datos.\nUn índice en R representa una posición.\nCuando usamos índices le pedimos a R que extraiga de una estructura los datos que se encuentran en una o varias posiciones específicas dentro de ella.\n\nEjemplos:\n\nSeleccionar la columna 2:\n\n\nmi_df [,2]\n\n[1] 1.2 3.4 4.5\n\n\nPara seleccionar una columna, también podemos usar el símbolo de $. Es bastante usado en varias funciones.\n\nmi_df$variable2\n\n[1] 1.2 3.4 4.5\n\n\n\nSeleccionar el caso (fila) 2:\n\n\nmi_df [2,]\n\n  variable1 variable2 variable3 variable4\n2         2       3.4         b         2\n\n\n\nSeleccionar el elemento que se encuentra en la fila 2 y la columna 2:\n\n\nmi_df [2,2]\n\n[1] 3.4\n\n\n\n\n1.2.8 Nuestras herramientas: Paquetes y funciones\nPAQUETES\nEn R, un paquete es un conjunto de herramientas y funciones predefinidas que permiten a los usuarios realizar tareas específicas, como análisis de datos o visualización de gráficos. Los paquetes pueden ser instalados desde los repositorios de CRAN u otros lugares (como repositorios).\nPara instalar un paquete necesitas escribir install.packages(\"nombre_del_paquete\"). Luego de instalarlo, para comenzar a utilizarlo debes abrirlo con el siguiente comando library(nombre_del_paquete).\nFUNCIONES\n\nLas funciones son bloques de código que realizan una tarea específica. Pueden ser definidas por el usuario o pueden ser proporcionadas por un paquete (esto es lo más común).\nLas funciones toman argumentos, que son valores que se pasan a la función para que los utilice en su tarea.\nLos argumentos de una función son variables o valores que se pasan a la función para que sean utilizados en la tarea que se está realizando. Algunos argumentos son obligatorios, lo que significa que deben ser proporcionados para que la función pueda realizar su tarea, mientras que otros son opcionales y tienen un valor predeterminado si no se especifican.\nPara ver qué argumentos tiene una función puedes entrar a la documentación de la misma.\nPor ejemplo, el paquete “dplyr” es un conjunto de herramientas que se utiliza para manipular y transformar datos en R. Una de las funciones de “dplyr” es “filter”, que se utiliza para filtrar filas en un conjunto de datos. Un argumento obligatorio para la función “filter” es el conjunto de datos que se va a filtrar, mientras que un argumento opcional es la condición que se utilizará para filtrar los datos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#sobre-r-y-r-studio",
    "href": "s1_intro.html#sobre-r-y-r-studio",
    "title": "1  Introducción",
    "section": "1.2 Sobre R y R Studio",
    "text": "1.2 Sobre R y R Studio\nR es un lenguaje de programación y un entorno de software libre orientado principalmente al análisis estadístico y la representación gráfica de datos. Desde su creación en 1993 por Ross Ihaka y Robert Gentleman en la Universidad de Auckland, R ha evolucionado para convertirse en una de las herramientas más populares y poderosas en el campo de la estadística y la ciencia de datos.\nAprender estadística con R tiene varias ventajas:\n\n\n\n\n\n\n\nVentaja\nDetalle\n\n\n\n\nFlexibilidad y Personalización\nR ofrece un amplio rango de análisis y permite la personalización y automatización según las necesidades del usuario.\n\n\nAmplio Repositorio de Paquetes\nLa comunidad de R ha desarrollado miles de paquetes, permitiendo fácil acceso a técnicas estadísticas avanzadas.\n\n\nReproducibilidad\nCon R, se pueden crear análisis que otros investigadores pueden verificar y replicar fácilmente.\n\n\nRepresentación Gráfica\nR destaca en la producción de gráficos de alta calidad, esenciales para la visualización de datos.\n\n\nComunidad Activa\nLa activa comunidad de R proporciona numerosos recursos, tutoriales y foros para el aprendizaje y resolución de dudas.\n\n\n\nLenguaje orientado a objetos\nR es un lenguaje de programación que adopta el paradigma de la “programación orientada a objetos”. Esto significa que, en R, todo se considera un “objeto”, ya sea un conjunto de datos, una función o un modelo. Cada objeto tiene atributos y comportamientos asociados que determinan cómo se puede interactuar con él. Esta estructura permite a los usuarios de R organizar y manipular datos de manera coherente y sistemática. Al entender que todo en R es un objeto, se puede abordar el análisis estadístico con una visión más estructurada, lo que facilita la comprensión y aplicación de técnicas y métodos avanzados en el futuro.\nImagina que cada objeto en R es como un coche. Los “atributos” de ese coche pueden incluir su color, marca, modelo, y año de fabricación. Estos atributos describen las características específicas del coche. Ahora, piensa en los “comportamientos asociados” como las acciones que puedes realizar con ese coche: encenderlo, acelerar, frenar o encender las luces. Del mismo modo, en R, un objeto, como un conjunto de datos, podría tener atributos que describan su tamaño, tipo y estructura. Y los comportamientos asociados de ese conjunto de datos podrían incluir operaciones como filtrar, ordenar o aplicar una función estadística.\nPor ejemplo, si tienes un objeto en R que es un dataframe (un tipo de estructura de datos tabular), sus “atributos” podrían incluir el número de filas y columnas, los nombres de las columnas y el tipo de datos en cada columna. Los “comportamientos asociados” de ese dataframe podrían ser operaciones como añadir o eliminar una columna, filtrar por ciertos valores o calcular estadísticas sobre una columna específica. Al comprender los atributos y comportamientos de los objetos en R, puedes manipularlos y analizarlos de manera efectiva y eficiente, al igual que un conductor experto sabe cómo manejar y cuidar su coche.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#objetos",
    "href": "s1_intro.html#objetos",
    "title": "1  Introducción",
    "section": "1.3 Objetos",
    "text": "1.3 Objetos\nVamos a examinar la clase de algunos de los elementos más básicos en R.\nUn objeto puede ser un número. En este caso el objeto es de tipo numeric.\n\n5\n\n[1] 5\n\n\nO también podría ser un nombre de un país. En este caso el objeto es de tipo character. Vas a notar que se trata de un caractér porque vas a visualizar el resultado entre comillas.\n\n\"Perú\"\n\n[1] \"Perú\"\n\n\nLos objetos también pueden almacenarse en la memoria con ciertos “nombres”. Por ejemplo:\n\nyear&lt;-2024\nyear\n\n[1] 2024\n\n\n\ncountry&lt;-\"Perú\"\ncountry\n\n[1] \"Perú\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nUno puede asignar un nombre a un objeto en el R con la flecha de asignación (&lt;-)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#vectores",
    "href": "s1_intro.html#vectores",
    "title": "1  Introducción",
    "section": "1.4 Vectores",
    "text": "1.4 Vectores\n\nUn vector es una colección de uno o más datos del mismo tipo.\nTipo. Un vector tiene el mismo tipo que los datos que contiene. Si tenemos un vector que contiene datos de tipo numérico, el vector será también de tipo numérico.\n\nEjemplo: Vamos a crear tres vectores: uno numérico, uno de caracter.\n\nvector_numerico &lt;- c(1, 2, 3, 4, 5)\nvector_numerico\n\n[1] 1 2 3 4 5\n\n\n\nvector_caracter &lt;- c(\"arbol\", \"casa\", \"persona\")\nvector_caracter\n\n[1] \"arbol\"   \"casa\"    \"persona\"",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#funciones",
    "href": "s1_intro.html#funciones",
    "title": "1  Introducción",
    "section": "1.5 Funciones",
    "text": "1.5 Funciones\nUna función es como una máquina a la que le das un insumo, o input para que realice un procedimiento específico. Luego de realizar el procedimiento, la máquina te da un resultado que le vamos a llamar output.\nPor ejemplo, podemos utilizar la función sqrt() para obtener la raíz cuadrada de un número. En este caso aplicamos una función sobre un sólo número.\n\nsqrt(16)\n\n[1] 4\n\n\nPero también podemos aplicar una función sobre un vector. Por ejemplo, podemos solicitar la función sum() para obtener la suma de todos los elementos de un vector numérico:\n\nsum(vector_numerico)\n\n[1] 15\n\n\nTambién podemos utilizar la función class() para corroborar que cada vector tiene la misma clase de los elementos que contiene.\n\nclass(vector_numerico)\n\n[1] \"numeric\"\n\nclass(vector_caracter)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nTe vas a dar cuenta que estás frente a una función porque usualmente está seguida de paréntesis en el cual se colocan los argumentos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#dataframes",
    "href": "s1_intro.html#dataframes",
    "title": "1  Introducción",
    "section": "1.6 Dataframes",
    "text": "1.6 Dataframes\nLos data frames son estructuras de datos de dos dimensiones (rectangulares) que pueden contener vectores de diferentes tipos.\nEs la estructura más usada para ciencia de datos y la que vamos a ver de forma más recurrente en el curso.\nLo más importante que debes recordar es que las filas en un dataframe representan casos, individuos u observaciones, mientras que las columnas representan atributos, rasgos o variables.\nPor ejemplo, tenemos la siguiente información sobre ciertos departamentos del Perú y sus niveles de pobreza:\n\ndepartamentos&lt;-c(\"Huancavelica\", \"Ayacucho\", \"Pasco\")\npobreza&lt;-c(47.7, 46.4, 44.8)\nmi_df&lt;-data.frame(departamentos, pobreza)\nmi_df\n\n  departamentos pobreza\n1  Huancavelica    47.7\n2      Ayacucho    46.4\n3         Pasco    44.8\n\n\nUna forma de examinar rápidamente un dataframe es utilizando la función str():\n\nstr(mi_df)\n\n'data.frame':   3 obs. of  2 variables:\n $ departamentos: chr  \"Huancavelica\" \"Ayacucho\" \"Pasco\"\n $ pobreza      : num  47.7 46.4 44.8\n\n\nEl output de esta función te indica las dimensiones del dataframe (número de observaciones y número de variables), así como los nombres de las variables, el tipo y algunos valores de muestra.\nOtra función básica para explorar es names(), la cual te arroja exclusivamente los nombres de las variables del dataframe:\n\nnames(mi_df)\n\n[1] \"departamentos\" \"pobreza\"",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#índices",
    "href": "s1_intro.html#índices",
    "title": "1  Introducción",
    "section": "1.7 Índices",
    "text": "1.7 Índices\n\nUsar índices para obtener subconjuntos es el procedimiento más universal en R, pues funciona para todas las estructuras de datos.\nUn índice en R representa una posición.\nCuando usamos índices le pedimos a R que extraiga de una estructura los datos que se encuentran en una o varias posiciones específicas dentro de ella.\n\nEjemplos:\n\nSeleccionar la columna 2:\n\n\nmi_df [,2]\n\n[1] 47.7 46.4 44.8\n\n\nPara seleccionar una columna, también podemos usar el símbolo de $. Es bastante usado en varias funciones.\n\nmi_df$pobreza\n\n[1] 47.7 46.4 44.8\n\n\n\nSeleccionar sólo el caso (fila) 2:\n\n\nmi_df [2,]\n\n  departamentos pobreza\n2      Ayacucho    46.4\n\n\n\nSeleccionar el elemento que se encuentra en la fila 2 y la columna 2:\n\n\nmi_df [2,2]\n\n[1] 46.4",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#paquetes",
    "href": "s1_intro.html#paquetes",
    "title": "1  Introducción",
    "section": "1.8 Paquetes",
    "text": "1.8 Paquetes\nEn R, un paquete es un conjunto de herramientas y funciones predefinidas que permiten a los usuarios realizar tareas específicas, como análisis de datos o visualización de gráficos. Los paquetes pueden ser instalados desde los repositorios de CRAN u otros lugares (como repositorios).\nPara instalar un paquete necesitas escribir install.packages(\"nombre_del_paquete\"). Luego de instalarlo, para comenzar a utilizarlo debes abrirlo con el siguiente comando library(nombre_del_paquete).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#objetivos-de-la-sesión",
    "href": "s1_intro.html#objetivos-de-la-sesión",
    "title": "1  Fundamentos de programación con R",
    "section": "",
    "text": "Al final de esta sesión, el estudiante será capaz de reconocer las características principales del programa R, incluyendo sus elementos básicos y los fundamentos para el análisis estadístico. Además, sabrá implementar los procedimientos básicos necesarios para iniciar cualquier análisis estadístico en R.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentos de programación con R</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#presentación",
    "href": "s1_intro.html#presentación",
    "title": "1  Fundamentos de programación con R",
    "section": "1.2 Presentación",
    "text": "1.2 Presentación",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentos de programación con R</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#sobre-r",
    "href": "s1_intro.html#sobre-r",
    "title": "1  Fundamentos de programación con R",
    "section": "1.3 Sobre R",
    "text": "1.3 Sobre R\n\n1.3.1 Consideraciones básicas\nR es un lenguaje de programación y un entorno de software libre orientado principalmente al análisis estadístico y la representación gráfica de datos.\nR es un lenguaje de programación que adopta el paradigma de la “programación orientada a objetos”. Esto significa que, en R, todo se considera un “objeto”, ya sea un número, una base de datos o un modelo estadístico.\nCada objeto tiene atributos y comportamientos asociados que determinan cómo se puede interactuar con él.\nImagina que cada objeto en R es como un coche. Los “atributos” de ese coche pueden incluir su color, marca, modelo, y año de fabricación. Estos atributos describen las características específicas del coche. Ahora, piensa en los “comportamientos asociados” como las acciones que puedes realizar con ese coche: encenderlo, acelerar, frenar o encender las luces. Del mismo modo, en R, un objeto, como un conjunto de datos, podría tener atributos que describan su tamaño, tipo y estructura. Y los comportamientos asociados de ese conjunto de datos podrían incluir operaciones como filtrar, ordenar o aplicar una función estadística.\n\n\n1.3.2 Cómo programar: Script\nExisten varias formas de escribir código en el R. Para ello tenemos algunas opciones simples, como el Script y otras un poco más elaboradas como el R Markdown.\nPara fines de esta primera clase vamos a utilizar el script, el cual es un documento de texto que tiene la peculiaridad que puede ser leídos por el programa como un manual de código. De esa forma, nosotros podemos colocar en el script los códigos de nuestro análisis, ordenarlos, comentarlos y reproducirlos en el R Studio automáticamente.\nEn suma, podemos redactar nuestros script, compartirlos con otros investigadores y ejecutarlos.\n\nComo comentario: Cuando nosotros colocamos el símbolo # al iniciar una oración, el Script lo va a identificar como un comentario del programador, como un texto que no va a ser ejecutado como código. Esto es importante porque nos permite ir comentando, por ejemplo, lo que estamos redactando en el documento. Ej: “Este código sirve para abrir un archivo”, “Aquí estoy haciendo un análisis de regresión”, entre otros.\nComo código: Cuando escribimos directamente en el documento el programa lo va a entender como código o funciones. Esto es importante tenerlo en cuenta para evitar notificaciones de Error.\n\nTe recomiendo ver el siguiente video para que puedas aprender más sobre el Script, pero también sobre las otras opciones que el R te puede ofrecer y que usaremos más adelante.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentos de programación con R</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#elementos-básicos",
    "href": "s1_intro.html#elementos-básicos",
    "title": "1  Fundamentos de programación con R",
    "section": "1.4 Elementos básicos",
    "text": "1.4 Elementos básicos\n\n1.4.1 Objetos\nVamos a examinar la clase de algunos de los elementos más básicos en R.\nUn objeto puede ser un número. En este caso el objeto es de tipo numeric.\n\n5\n\n[1] 5\n\n\nO también podría ser un nombre de un país. En este caso el objeto es de tipo character. Vas a notar que se trata de un caractér porque vas a visualizar el resultado entre comillas.\n\n\"Perú\"\n\n[1] \"Perú\"\n\n\nLos objetos también pueden almacenarse en la memoria del programa con ciertos “nombres”. Por ejemplo:\n\nyear&lt;-2024\nyear\n\n[1] 2024\n\n\n\ncountry&lt;-\"Perú\"\ncountry\n\n[1] \"Perú\"\n\n\nUno puede asignar un nombre a un objeto en el R con la flecha de asignación (&lt;-)\n\n\n\n\n\n\nImportante\n\n\n\nEn la próxima clase, exploraremos otro tipo de objetos conocidos como factores.\n\n\n\n\n1.4.2 Vectores\n\nUn vector es una colección de uno o más datos del mismo tipo.\nTipo. Un vector tiene el mismo tipo que los datos que contiene. Si tenemos un vector que contiene datos de tipo numérico, el vector será también de tipo numérico.\n\nEjemplo: Vamos a crear tres vectores: uno numérico, uno de caracter.\n\nvector_numerico &lt;- c(1, 2, 3, 4, 5)\nvector_numerico\n\n[1] 1 2 3 4 5\n\n\n\nvector_caracter &lt;- c(\"arbol\", \"casa\", \"persona\")\nvector_caracter\n\n[1] \"arbol\"   \"casa\"    \"persona\"\n\n\n\n\n1.4.3 Funciones\nUna función es como una máquina a la que le das un insumo, o input para que realice un procedimiento específico. Luego de realizar el procedimiento, la máquina te da un resultado que le vamos a llamar output.\nPor ejemplo, podemos utilizar la función sqrt() para obtener la raíz cuadrada de un número. En este caso aplicamos una función sobre un sólo número.\n\nsqrt(16)\n\n[1] 4\n\n\nPero también podemos aplicar una función sobre un vector. Por ejemplo, podemos solicitar la función sum() para obtener la suma de todos los elementos de un vector numérico:\n\nsum(vector_numerico)\n\n[1] 15\n\n\nTambién podemos utilizar la función class() para corroborar que la clase del vector que tenemos.\n\nclass(vector_numerico)\n\n[1] \"numeric\"\n\nclass(vector_caracter)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nSiempre te vas a dar cuenta que estás frente a una función porque usualmente está seguida de paréntesis en el cual se colocan los argumentos.\n\n\n\n\n1.4.4 Dataframes\nLos data frames son estructuras de datos de dos dimensiones (rectangulares) que pueden contener vectores de diferentes tipos.\nEs la estructura más usada para ciencia de datos y la que vamos a ver de forma más recurrente en el curso.\nLo más importante que debes recordar es que las filas en un dataframe representan casos, individuos u observaciones, mientras que las columnas representan atributos, rasgos o variables.\nPor ejemplo, tenemos la siguiente información sobre ciertos departamentos del Perú y sus niveles de pobreza:\n\ndepartamentos&lt;-c(\"Huancavelica\", \"Ayacucho\", \"Pasco\")\npobreza&lt;-c(47.7, 46.4, 44.8)\nmi_df&lt;-data.frame(departamentos, pobreza)\nmi_df\n\n  departamentos pobreza\n1  Huancavelica    47.7\n2      Ayacucho    46.4\n3         Pasco    44.8\n\n\nUna forma de examinar rápidamente un dataframe es utilizando la función str():\n\nstr(mi_df)\n\n'data.frame':   3 obs. of  2 variables:\n $ departamentos: chr  \"Huancavelica\" \"Ayacucho\" \"Pasco\"\n $ pobreza      : num  47.7 46.4 44.8\n\n\nEl output de esta función te indica las dimensiones del dataframe (número de observaciones y número de variables), así como los nombres de las variables, el tipo y algunos valores de muestra.\nOtra función básica para explorar es names(), la cual te arroja exclusivamente los nombres de las variables del dataframe:\n\nnames(mi_df)\n\n[1] \"departamentos\" \"pobreza\"      \n\n\n\n\n\n\n\n\nImportante\n\n\n\nUn error frecuente es no identificar correctamente las unidades de análisis con las que estamos trabajando. Al abrir un conjunto de datos, lo primero que debes preguntarte es: ¿A qué se refiere esta información? ¿A personas, países, instituciones?\n\n\n\n\n1.4.5 Índices\n\nUsar índices para obtener subconjuntos es el procedimiento más universal en R, pues funciona para todas las estructuras de datos.\nUn índice en R representa una posición.\nCuando usamos índices le pedimos a R que extraiga de una estructura los datos que se encuentran en una o varias posiciones específicas dentro de ella.\n\nEjemplos:\n\nSeleccionar la columna 2:\n\n\nmi_df [,2]\n\n[1] 47.7 46.4 44.8\n\n\nPara seleccionar una columna, también podemos usar el símbolo de $.\n\nmi_df$pobreza\n\n[1] 47.7 46.4 44.8\n\n\nNormalmente lo usamos cuando queremos aplicar una función a sólo una columna. Como por ejemplo:\n\nmean(mi_df$pobreza)\n\n[1] 46.3\n\n\n\nSeleccionar sólo el caso (fila) 2:\n\n\nmi_df [2,]\n\n  departamentos pobreza\n2      Ayacucho    46.4\n\n\n\nSeleccionar el elemento que se encuentra en la fila 2 y la columna 2:\n\n\nmi_df [2,2]\n\n[1] 46.4\n\n\n\n\n\n\n\n\nTip\n\n\n\nRecuerda que en los [,] primero se mencionan las filas y luego las columnas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentos de programación con R</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#procedimientos-básicos",
    "href": "s1_intro.html#procedimientos-básicos",
    "title": "1  Fundamentos de programación con R",
    "section": "1.5 Procedimientos básicos",
    "text": "1.5 Procedimientos básicos\nHasta aquí hemos aprendido los elementos básicos del R, ahora procederemos a analizar los procedimientos más cotidianos que realizaremos en un proceso de análisis de datos estadísticos.\n\n1.5.1 Apertura de paquetes\nLíneas arriba te había comentado que existían funciones que podías aplicar sobre objetos en el R. Dabas un input y la función te arrojaba un determinado resultado.\nAhora bien, lo más interesante del R es que existen diferentes “conjuntos de funciones” para tareas específicas y que uno puede instalar y utilizar en tu proceso de análisis.\nPara instalar un paquete necesitas escribir install.packages(\"nombre_del_paquete\"). Luego de instalarlo, para comenzar a utilizarlo debes abrirlo con el siguiente comando library(nombre_del_paquete).\nHagamos la prueba con el paquete rio, el cual es un paquete creado para importar/exportar archivos de diversos tipos.\nPrimero lo vamos a instalar. No te olvides que cuando instalas un paquete el nombre del mismo va entre comillas:\n\n#install.packages(\"rio\")\n\n\n\n\n\n\n\nTip\n\n\n\nRecuerda que la instalación de paquetes se realiza sólo una vez. Esto quiere decir que si instalas hoy el paquete “rio” ya no será necesario que realices esta operación nuevamente.\n\n\nLuego de instalarlo lo debemos abrir para utilizar las funciones que están dentro de él.\n\nlibrary(rio)\n\n\n\n1.5.2 Apertura de archivos\nLo más común es que se te va a entregar un archivo para que lo puedas abrir en el R.\nPara ello, una primera forma sencilla de abrir un archivo es haciendo uso de la función import del paquete rio:\n\ndata&lt;-import(\"data/regiones.xlsx\") \n#Dentro del () colocas la ubicación del archivo.\n\nUna vez que abrimos una data y corroboramos que está en nuestro Environment podemos explorarla.\nViendo un encabezado de las primeras filas:\n\nhead(data)\n\n     region macroregion poblacion pobreza nivel_pobreza  agua desague\n1  Amazonas     Oriente    379384    47.3             3 51.84   36.69\n2    Ancash       Norte   1083519    23.5             2 71.56   56.38\n3  Apurímac         Sur    405759    42.8             3 56.33   36.12\n4  Arequipa         Sur   1382730     9.1             1 72.47   65.85\n5  Ayacucho         Sur    616176    51.9             3 66.99   45.35\n6 Cajamarca       Norte   1341012    52.9             3 52.89   32.48\n  electrificacion acceso_internet telefonia_movil pc_tablet hospitales\n1           73.67            4.45           69.39     11.02          8\n2           85.20           18.33           79.60     25.00         23\n3           80.43            8.93           71.21     14.74          8\n4           89.98           32.88           91.28     40.52         24\n5           80.94           10.42           77.65     17.84         11\n6           80.68            9.29           74.66     14.10         25\n\n\nAnalizando su estructura:\n\nstr(data)\n\n'data.frame':   24 obs. of  12 variables:\n $ region         : chr  \"Amazonas\" \"Ancash\" \"Apurímac\" \"Arequipa\" ...\n $ macroregion    : chr  \"Oriente\" \"Norte\" \"Sur\" \"Sur\" ...\n $ poblacion      : num  379384 1083519 405759 1382730 616176 ...\n $ pobreza        : num  47.3 23.5 42.8 9.1 51.9 52.9 18.8 46.6 40.1 4.7 ...\n $ nivel_pobreza  : num  3 2 3 1 3 3 2 3 3 1 ...\n $ agua           : num  51.8 71.6 56.3 72.5 67 ...\n $ desague        : num  36.7 56.4 36.1 65.8 45.4 ...\n $ electrificacion: num  73.7 85.2 80.4 90 80.9 ...\n $ acceso_internet: num  4.45 18.33 8.93 32.88 10.42 ...\n $ telefonia_movil: num  69.4 79.6 71.2 91.3 77.7 ...\n $ pc_tablet      : num  11 25 14.7 40.5 17.8 ...\n $ hospitales     : num  8 23 8 24 11 25 20 5 9 25 ...\n\n\n\nnames(data)\n\n [1] \"region\"          \"macroregion\"     \"poblacion\"       \"pobreza\"        \n [5] \"nivel_pobreza\"   \"agua\"            \"desague\"         \"electrificacion\"\n [9] \"acceso_internet\" \"telefonia_movil\" \"pc_tablet\"       \"hospitales\"     \n\n\n\n\n1.5.3 Identificación teórica de la variable\n\nAntes de seguir en el análisis debemos corroborar los tipos de variables con los que estamos trabajando a nivel teórico.\nEn una data real, esto normalmente lo encontramos en el Cuestionario o Diccionario de Variables. Según la teoría estadistica podemos tener dos grandes opciones.\n\n1.5.3.1 Numéricas\nLas variables numéricas son aquellas que representan cantidades medidas o contadas, y pueden ser de tipo entero o decimal. Permiten realizar operaciones matemáticas y son fundamentales en el análisis estadístico y cuantitativo.\nSe clasifican en continuas y discretas, basándose en los valores que pueden tomar.\nLas variables discretas representan información que se puede contar en unidades enteras, como el número de hospitales en nuestra base de datos.\nPor otro lado, las variables continuas pueden tomar cualquier valor dentro de un rango, incluyendo decimales. En nuestra base de datos contamos con variables como * como la altura o el peso pobreza, agua, entre otros. Esto significa que pueden medir con precisión infinita dentro de su escala, adaptándose a una variedad más amplia de datos y mediciones.\n\n\n1.5.3.2 Categóricas\nUna variable categórica clasifica las observaciones en grupos o categorías que no tienen un orden matemático inherente. Se dividen en nominales y ordinales.\nLas variables nominales representan categorías sin un orden específico entre ellas, como colores, nombres de países o géneros. En nuestra data una variable nominal sería macroregion.\nEn cambio, las variables ordinales sí poseen un orden o jerarquía entre las categorías, aunque la distancia entre estas no es necesariamente uniforme; por ejemplo, niveles de educación o calificaciones de satisfacción. Continuando con el ejemplo, la variable ordinal nivel_pobreza clasifica en categorías donde el 1 corresponde a “Bajo”, el 2 a “Medio” y el 3 a “Alto”.\n\n\n\n1.5.4 Configuración de las variable en R\nAhora veamos qué tenemos en nuestra data.\nVeamos las siguientes tres variables: poblacion (numérica), macroregión (nominal) y nivel de pobreza (ordinal).\nDichas variables qué tipo de objeto son actualmente en el R?\n\n1.5.4.1 Numeric\n\nclass(data$poblacion)\n\n[1] \"numeric\"\n\n\nPara el caso de población cuenta con la configuración adecuada pues es numeric.\nTen en cuenta que para el caso de una variable numérica discreta como hospitales la configuración adecuada también es numeric.\n\n\n1.5.4.2 Factors\nPara el caso de las variables categóricas, para poder trabajar con estas en el R debemos convertirlas a un tipo especial de objeto denominado factor.\nBásicamente, un factor es una variable que tiene grupos, los cuales pueden estar ordenados o no ordenados.\nFACTORES NO ORDENADOS\nPara el caso de la variable nominal macroregión que inicialmente está mal configurada (pues tiene el tipo character).\n\nclass(data$macroregion)\n\n[1] \"character\"\n\n\nvamos a convertirla en un factor no ordenado.\n\ndata$macroregion&lt;-factor(data$macroregion)\n\n\n\n\n\n\n\nTip\n\n\n\nHemos empleado la función factor() y el operador de asignación porque estamos modificando una parte de nuestro conjunto de datos. En otras palabras, estamos actualizando la variable macroregión con su configuración correcta.\n\n\nPodemos corroborar el tipo final pidiendo otra vez la función str():\n\nstr(data$macroregion)\n\n Factor w/ 4 levels \"Centro\",\"Norte\",..: 3 2 4 4 4 2 4 1 1 1 ...\n\n\nEn este caso nos menciona que ahora la variable macroregion es un factor con cuatro niveles (Centro, Norte, Sur, Oriente).\n\n\n\n\n\n\nImportante\n\n\n\nSi bien aquí vemos la palabra “niveles” esto no quiere decir que para R esos niveles tengan un orden, sino más bien que son categorías diferentes.\n\n\nFACTORES ORDENADOS\nAhora bien, el caso del nivel de pobreza es diferente, ya que, aunque también es un factor, sus niveles presentan un orden de magnitud específico.\nEn este caso, además de convertirla en factor, es necesario especificar el orden de los niveles, indicando que efectivamente se trata de una secuencia ordenada.\n\ndata$nivel_pobreza&lt;-factor(data$nivel_pobreza,\n                          levels = c(1,2,3),\n                          ordered = TRUE)\n\nMediante la función str(), confirmamos que nuestra variable nivel_pobreza se ha convertido efectivamente en un factor ordenado con tres niveles, donde 1 es menor que 2 y, a su vez, 2 es menor que 3.\n\nstr(data$nivel_pobreza)\n\n Ord.factor w/ 3 levels \"1\"&lt;\"2\"&lt;\"3\": 3 2 3 1 3 3 2 3 3 1 ...\n\n\n\n\n\n\n\n\nImportante\n\n\n\nAunque para nosotros los niveles parecen ser números (1, 2 o 3), para R no lo son. Esto significa que no es posible realizar operaciones matemáticas con ellos.\n\n\nAhora con esta configuración ya estamos listos para el siguiente paso: manipular tablas y calculas estadísticos descriptivos.\n\nstr(data)\n\n'data.frame':   24 obs. of  12 variables:\n $ region         : chr  \"Amazonas\" \"Ancash\" \"Apurímac\" \"Arequipa\" ...\n $ macroregion    : Factor w/ 4 levels \"Centro\",\"Norte\",..: 3 2 4 4 4 2 4 1 1 1 ...\n $ poblacion      : num  379384 1083519 405759 1382730 616176 ...\n $ pobreza        : num  47.3 23.5 42.8 9.1 51.9 52.9 18.8 46.6 40.1 4.7 ...\n $ nivel_pobreza  : Ord.factor w/ 3 levels \"1\"&lt;\"2\"&lt;\"3\": 3 2 3 1 3 3 2 3 3 1 ...\n $ agua           : num  51.8 71.6 56.3 72.5 67 ...\n $ desague        : num  36.7 56.4 36.1 65.8 45.4 ...\n $ electrificacion: num  73.7 85.2 80.4 90 80.9 ...\n $ acceso_internet: num  4.45 18.33 8.93 32.88 10.42 ...\n $ telefonia_movil: num  69.4 79.6 71.2 91.3 77.7 ...\n $ pc_tablet      : num  11 25 14.7 40.5 17.8 ...\n $ hospitales     : num  8 23 8 24 11 25 20 5 9 25 ...",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentos de programación con R</span>"
    ]
  },
  {
    "objectID": "index.html#sobre-ia-generativa",
    "href": "index.html#sobre-ia-generativa",
    "title": "Estadística para el Análisis Político 1",
    "section": "Sobre IA generativa",
    "text": "Sobre IA generativa\nPermitimos y promovemos activamente el uso de inteligencia artificial generativa, como ChatGPT, Gemini, y otras plataformas similares, como soporte para la creación y sofisticación del código en R.\nCreemos firmemente que estas herramientas pueden ser aliados significativos para profundizar en la comprensión de conceptos complejos, mejorar las habilidades de programación y fomentar la innovación y creatividad en nuestros proyectos y tareas.\nLa integración de la inteligencia artificial en nuestro proceso de aprendizaje ofrece una oportunidad única para experimentar con nuevas formas de resolver problemas, optimizar procesos y generar ideas que puedan llevar nuestra capacidad analítica y técnica a nuevos niveles.\nSin embargo, es importante destacar que, mientras fomentamos el uso de estas herramientas tecnológicas avanzadas para la exploración y el aprendizaje durante el curso, no se permitirá su uso en las evaluaciones.",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "index.html#software",
    "href": "index.html#software",
    "title": "Estadística para el Análisis Político 1",
    "section": "Software",
    "text": "Software\nTanto en las sesiones teóricas, como en las prácticas, se hará uso del software libre R y de la interfase Rstudio. Se requiere descargar las últimas versiones de ambos programas informáticos.\nLa última versión de R (4.3.3) puede ser descargada gratuitamente para Windows o macOS.\nhttps://cran.r-project.org/bin/windows/base/\nhttps://cran.r-project.org/bin/macosx/\nLa última versión de Rstudio Desktop (versión RStudio 2023.12.1+402) puede ser descargada aquí para Windows o macOS.\nhttps://posit.co/download/rstudio-desktop/",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "s1_intro.html#resumen",
    "href": "s1_intro.html#resumen",
    "title": "1  Fundamentos de programación con R",
    "section": "1.6 Resumen",
    "text": "1.6 Resumen",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentos de programación con R</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html#objetivos-de-la-sesión",
    "href": "s2_descriptivo.html#objetivos-de-la-sesión",
    "title": "2  Manipulación de tablas",
    "section": "",
    "text": "Al final de esta sesión, el estudiante será capaz de manipular un dataframe a fin de editarlo de acuerdo a su necesidad utilizando algunos verbos básicos del paquete dplyr. También podrá solicitar algunos de los principales estadísticos descriptivos de tendencia central.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html#presentación",
    "href": "s2_descriptivo.html#presentación",
    "title": "2  Manipulación de tablas",
    "section": "2.2 Presentación",
    "text": "2.2 Presentación",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html#manipulación-de-datos",
    "href": "s2_descriptivo.html#manipulación-de-datos",
    "title": "2  Estadística Descriptiva I",
    "section": "2.3 Manipulación de datos",
    "text": "2.3 Manipulación de datos\nIn summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estadística Descriptiva I</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html#resumen",
    "href": "s2_descriptivo.html#resumen",
    "title": "2  Manipulación de tablas",
    "section": "2.6 Resumen",
    "text": "2.6 Resumen",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html#introducción-al-tidyverse",
    "href": "s2_descriptivo.html#introducción-al-tidyverse",
    "title": "2  Manipulación de tablas",
    "section": "2.3 Introducción al Tidyverse",
    "text": "2.3 Introducción al Tidyverse\nEl tidyverse es una colección de paquetes de R diseñados para la ciencia de datos que comparten una filosofía subyacente y son interoperables, facilitando la importación, manipulación, exploración y visualización de datos.\nTe sugiero ver este video introductorio sobre el Tidyverse:\n\nAbrimos la librería tidyverse:\n\nlibrary(tidyverse)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html#manipulación-de-datos-con-dplyr",
    "href": "s2_descriptivo.html#manipulación-de-datos-con-dplyr",
    "title": "2  Manipulación de tablas",
    "section": "2.4 Manipulación de datos con dplyr",
    "text": "2.4 Manipulación de datos con dplyr\ndplyr es un paquete del Tidyverse que sirve para manipular tablas y transformarlas. Tiene una amplia gama de verbos con los cuales podemos realizar las tareas más recurrentes de la manipulación de datos.\n\n\n2.4.1 Problema de investigación y data\n\nEl Índice de Percepción de la Corrupción (CPI, por sus siglas en inglés) es una herramienta global que clasifica a los países según la percepción de corrupción en el sector público, basándose en evaluaciones de expertos y encuestas de negocios. La escala va de 0 (muy corrupto) a 100 (muy limpio), y sirve para comparar la situación de corrupción entre diferentes naciones. Es publicado anualmente por Transparency International, una organización no gubernamental dedicada a combatir la corrupción global.\nExaminemos la base original. Vamos a editar la tabla con diversos verbos de dplyr.\nAbrir archivo\nAbrimos el archivo con el paquete `rio``:\n\nlibrary(rio)\ndata_con_rio&lt;-import(\"data/CPI.xlsx\")\n\nTen en cuenta que en el R también existen otros paquetes como readr, haven o readxl que también te permiten abrir archivos de distintos formatos.\nPor ejemplo, podríamos abrir este archivo con la función read_xlsx():\n\nlibrary(readxl)\ndata&lt;-read_xlsx(\"data/CPI.xlsx\")\n\nPodemos ver las datas (y las diferencias que trae abrirlas con uno u otro paquete):\n\n#data_con_rio\nclass(data_con_rio)\n\n[1] \"data.frame\"\n\n\n\ndata\n\n# A tibble: 1,086 × 5\n   country               year iso3  region cpi_score\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Afghanistan           2022 AFG   AP            24\n 2 Albania               2022 ALB   ECA           36\n 3 United Arab Emirates  2022 ARE   MENA          67\n 4 Angola                2022 AGO   SSA           33\n 5 Argentina             2022 ARG   AME           38\n 6 Armenia               2022 ARM   ECA           46\n 7 Australia             2022 AUS   AP            75\n 8 Austria               2022 AUT   WE/EU         71\n 9 Azerbaijan            2022 AZE   ECA           23\n10 Bahamas               2022 BHS   AME           64\n# ℹ 1,076 more rows\n\nclass(data)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n\n\n\n\nNota\n\n\n\nUn tibble es una versión moderna del dataframe en R, parte del tidyverse, diseñado para facilitar el trabajo con datos tabulares.\n\n\nExploración del dataset y configuración de variables\nVemos la estructura rápidamente:\n\nstr(data)\n\ntibble [1,086 × 5] (S3: tbl_df/tbl/data.frame)\n $ country  : chr [1:1086] \"Afghanistan\" \"Albania\" \"United Arab Emirates\" \"Angola\" ...\n $ year     : num [1:1086] 2022 2022 2022 2022 2022 ...\n $ iso3     : chr [1:1086] \"AFG\" \"ALB\" \"ARE\" \"AGO\" ...\n $ region   : chr [1:1086] \"AP\" \"ECA\" \"MENA\" \"SSA\" ...\n $ cpi_score: num [1:1086] 24 36 67 33 38 46 75 71 23 64 ...\n\n\nAl ejecutar names() sobre un conjunto de datos, se nos devuelve un vector con los nombres de todas las columnas en el orden en que aparecen.\n\nnames(data)\n\n[1] \"country\"   \"year\"      \"iso3\"      \"region\"    \"cpi_score\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nAntes de proseguir con el análisis descriptivo, es fundamental que comprendas claramente qué representan las filas y las columnas en tus datos.\n\n\nCorroboramos que el score del CPI esté adecuadamente configurado.\n\nclass(data$cpi_score)\n\n[1] \"numeric\"\n\n\nDe acuerdo, podemos proseguir.\n\n\n2.4.2 Select()\nLa función select() es utilizada para seleccionar o excluir columnas de un data frame o tibble en R. Va más allá de simplemente escoger columnas por nombre, ya que permite una amplia gama de criterios y operaciones.\nFuncionamiento básico:\n\nEntrada: Un data frame o tibble y un conjunto de nombres de columnas o criterios para seleccionar columnas.\nSalida: Un objeto de la misma clase que el de entrada (data frame o tibble) que contiene solo las columnas seleccionadas.\n\nVamos a seleccionar sólo ciertas columnas:\n\ndata1&lt;-data |&gt; \n  select(country, year, region, cpi_score)\ndata1\n\n# A tibble: 1,086 × 4\n   country               year region cpi_score\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Afghanistan           2022 AP            24\n 2 Albania               2022 ECA           36\n 3 United Arab Emirates  2022 MENA          67\n 4 Angola                2022 SSA           33\n 5 Argentina             2022 AME           38\n 6 Armenia               2022 ECA           46\n 7 Australia             2022 AP            75\n 8 Austria               2022 WE/EU         71\n 9 Azerbaijan            2022 ECA           23\n10 Bahamas               2022 AME           64\n# ℹ 1,076 more rows\n\n\nTener en cuenta que puedes:\n\nSeleccionar por nombre\nSeleccionar por el número de la columna\n(Des)seleccionar colocando un “-” antes del nombre/número de columna.\nSeleccionar un rango colocando por ejemplo 2:4 lo que significa “desde la columna 2 hasta la columna 4).\nPuedes combinar todas las anteriores y tener más de un criterio a la vez separándolo por coma.\n\n\n\n2.4.3 Filter()\nLa función filter() se utiliza para filtrar filas de un data frame o tibble en R en función de condiciones específicas, permitiendo crear un subconjunto de datos.\nAl crear subconjuntos nuestros datos de forma precisa, podemos focalizar nuestro análisis, mejorar la eficiencia computacional y obtener resultados más claros y relevantes.\nCaracterísticas principales:\n\nCondiciones múltiples: Puedes usar múltiples condiciones para filtrar tus datos. Estas se combinan utilizando operadores lógicos como & (y), | (o) y ! (no).\nUso de operadores de comparación: Los operadores estándar como ==, &gt;, &lt;, &gt;=, &lt;=, y != se utilizan para establecer condiciones.\nFunciones auxiliares: dplyr proporciona funciones como between(), que pueden ser útiles para establecer condiciones. Por ejemplo, between(x, 1, 10) es equivalente a x &gt;= 1 & x &lt;= 10.\n\nEn este caso vamos a seleccionar aquellos países cuya medición es del año 2022.\n\ndata2&lt;-data1 %&gt;%                   \n  filter(year==2022)\ndata2\n\n# A tibble: 181 × 4\n   country               year region cpi_score\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Afghanistan           2022 AP            24\n 2 Albania               2022 ECA           36\n 3 United Arab Emirates  2022 MENA          67\n 4 Angola                2022 SSA           33\n 5 Argentina             2022 AME           38\n 6 Armenia               2022 ECA           46\n 7 Australia             2022 AP            75\n 8 Austria               2022 WE/EU         71\n 9 Azerbaijan            2022 ECA           23\n10 Bahamas               2022 AME           64\n# ℹ 171 more rows\n\n\n\n\n2.4.4 Arrange()\nSe utiliza para ordenar (o reordenar) un data frame o tibble según una o más columnas.\nFuncionamiento básico:\n\nOrdenación simple: Si proporcionas una columna a arrange(), ordenará el data frame en función de esa columna en orden ascendente por defecto.\nOrdenación descendente: Si deseas ordenar en dirección descendente, puedes usar la función desc(). Por ejemplo: df |&gt; arrange(desc(edad)) ordenará el data frame por la columna “edad” en orden descendente.\nOrdenación múltiple: Puedes proporcionar múltiples columnas para ordenar, y arrange() las usará en el orden proporcionado para determinar el ordenamiento. Por ejemplo, si deseas ordenar primero por “grupo” y luego por “edad” dentro de cada grupo, usarías: df |&gt; arrange(grupo, edad).\n\n\ndata3&lt;-data2 |&gt;    \n  arrange(desc(cpi_score))\ndata3\n\n# A tibble: 181 × 4\n   country      year region cpi_score\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU         90\n 2 Finland      2022 WE/EU         87\n 3 New Zealand  2022 AP            87\n 4 Norway       2022 WE/EU         84\n 5 Singapore    2022 AP            83\n 6 Sweden       2022 WE/EU         83\n 7 Switzerland  2022 WE/EU         82\n 8 Netherlands  2022 WE/EU         80\n 9 Germany      2022 WE/EU         79\n10 Ireland      2022 WE/EU         77\n# ℹ 171 more rows\n\n\n\n\n2.4.5 Mutate()\nLa función mutate() está diseñada para crear o modificar columnas dentro de un data frame o tibble en R. Mientras que el data frame original se mantiene inalterado, mutate() devuelve una copia con las columnas especificadas añadidas o alteradas.\nEn este caso vamos a crear una variable cambiando la escala del score del CPI.\nEn la medida original 0 representaba alta corrupción y 100 escasa corrupción. Ahora, si realizamos la operación “100 - cpi_score”, los valores cercanos a 0 tendrán poca corrupción y los cercanos a 100 alta corrupción, siendo más intuitivo.\nEsta transformación puede ser útil para ajustar la interpretación de los datos a contextos donde es más intuitivo trabajar con escalas donde un número mayor indica mayor intensidad de un fenómeno (Corrupción, en este caso), dependiendo del análisis que se desea realizar.\n\ndata4&lt;-data3 |&gt;   \n  mutate(cpi_score2=100-cpi_score) \ndata4\n\n# A tibble: 181 × 5\n   country      year region cpi_score cpi_score2\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU         90         10\n 2 Finland      2022 WE/EU         87         13\n 3 New Zealand  2022 AP            87         13\n 4 Norway       2022 WE/EU         84         16\n 5 Singapore    2022 AP            83         17\n 6 Sweden       2022 WE/EU         83         17\n 7 Switzerland  2022 WE/EU         82         18\n 8 Netherlands  2022 WE/EU         80         20\n 9 Germany      2022 WE/EU         79         21\n10 Ireland      2022 WE/EU         77         23\n# ℹ 171 more rows\n\n\n\n\n2.4.6 Summarise()\nSe utiliza para crear resúmenes estadísticos de un data frame o tibble.\nDentro de los resúmenes puedes disponer de por ejemplo:\nMedidas de tendencia central: Estas funciones describen un valor central o típico dentro de un conjunto de datos.\n\nMedia: mean(x)\nMediana: median(x)\n\nCómo calcularíamos la media de forma directa (tradicional)?\n\nsummary(data4$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  10.00   45.00   60.50   57.02   70.25   88.00       1 \n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\n¿Qué significa NA´s? ¿Por qué se produce esto en una data como la de Corruption Perception Index?\n\n\nCómo lo calculamos con tidyverse?\n\ndata4 |&gt;   \n  summarise(mean(cpi_score2, na.rm = T))    \n\n# A tibble: 1 × 1\n  `mean(cpi_score2, na.rm = T)`\n                          &lt;dbl&gt;\n1                          57.0\n\n\n\n\n\n\n\n\nNota\n\n\n\nCuando aplicamos un summarise lo que nos devuelve es un valor o conjunto de valores. Por otro lado, el argumento na.rm = TRUE se utiliza para especificar que los valores perdidos (NA) deben ser ignorados en el cálculo. De esta forma, le indicamos a la función que proceda con la operación excluyendo dichos valores ausentes.\n\n\n\n\n2.4.7 Utilizando pipe: |&gt;\nProbablemente hayas observado que hemos creado un conjunto de datos para cada verbo utilizado, lo cual en situaciones reales resultaría excesivamente repetitivo. Haciendo una analogía con la escritura de un libro, sería como si estuviéramos limitados a usar únicamente oraciones, lo cual haría el proceso tedioso.\nEl operador |&gt; (pipe) en R, introducido en la versión 4.1, permite realizar operaciones en cadena, facilitando la secuencia de funciones y transformaciones en un flujo más legible y ordenado.\nEs evidente que, mediante el uso del operador pipe, podemos encadenar verbos de manera fluida y evitar la creación innecesaria de objetos, ya que este operador permite que el resultado a la izquierda se convierta automáticamente en el argumento de la función a la derecha.\n\ndata |&gt;\n  select(country, year, region, cpi_score) |&gt; \n  filter(year==2022) |&gt; \n  arrange(desc(cpi_score)) |&gt; \n  mutate(cpi_score2=100-cpi_score) |&gt; \n  summarise(mean(cpi_score2, na.rm=T))  \n\n# A tibble: 1 × 1\n  `mean(cpi_score2, na.rm = T)`\n                          &lt;dbl&gt;\n1                          57.0\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\n¿Qué sucede si a esta cadena de pipes le doy un nombre? ¿Cuál sería el objeto creado?\n\n\n\ndata_final&lt;-data |&gt;\n  select(country, year, region, cpi_score) |&gt; \n  filter(year==2022) |&gt;\n  arrange(desc(cpi_score)) |&gt;\n  mutate(cpi_score2=100-cpi_score)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html#funciones-complementarias-group_by-count-rename-y-case_when",
    "href": "s2_descriptivo.html#funciones-complementarias-group_by-count-rename-y-case_when",
    "title": "2  Manipulación de tablas",
    "section": "2.5 Funciones complementarias: group_by(), count(), rename() y case_when()",
    "text": "2.5 Funciones complementarias: group_by(), count(), rename() y case_when()\n\n2.5.1 Agrupando con group_by()\nSe utiliza para dividir un conjunto de datos en grupos según valores de una o más variables (normalmente de tipo categórica). Una vez que los datos están agrupados, es posible realizar operaciones específicas dentro de cada grupo.\n\ndata |&gt;   \n  group_by(year) |&gt; \n  summarise(Media=mean(cpi_score, na.rm = T)) \n\n# A tibble: 6 × 2\n   year Media\n  &lt;dbl&gt; &lt;dbl&gt;\n1  2017  43.1\n2  2018  43.1\n3  2019  43.2\n4  2020  43.3\n5  2021  43.3\n6  2022  43.0\n\n\n\n\n2.5.2 Contar con count()\nFacilita el conteo de observaciones dentro de categorías específicas de una o más variables en un dataframe. Esta función agrupa el conjunto de datos por las variables especificadas y luego calcula el número de observaciones dentro de cada categoría, retornando un nuevo dataframe con las categorías y sus respectivos conteos. Es una herramienta esencial para obtener resúmenes rápidos y frecuencias de variables categóricas en datos estructurados.\n\ndata_final |&gt;   \n  count(region) |&gt;  \n  arrange(desc(n))  \n\n# A tibble: 6 × 2\n  region     n\n  &lt;chr&gt;  &lt;int&gt;\n1 SSA       49\n2 AME       32\n3 AP        32\n4 WE/EU     31\n5 ECA       19\n6 MENA      18\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn la última línea de código, indicamos a R que ordene los datos de acuerdo a la variable ‘n’, la cual fue definida en la línea de código precedente. Es importante recordar que la ejecución de acciones o funciones en R se realiza de manera secuencial y acumulativa.\n\n\n\n\n2.5.3 Renombrar con rename()\nPermite cambiar los nombres de las columnas de un dataframe. Para ello, se especifica el nuevo nombre deseado y el nombre actual de la columna. Esta función es útil cuando se necesita ajustar o estandarizar los nombres de las columnas en un conjunto de datos, facilitando así análisis posteriores y asegurando la claridad y consistencia en la manipulación de los datos.\nPrimero debes escribir el nuevo nombre y luego el nombre original de la variable.\n\ndata_final |&gt;   \n  rename(zona=region)   # Renombro la columna \"region\" (nombre original) como \"zona\" (nombre nuevo)\n\n# A tibble: 181 × 5\n   country      year zona  cpi_score cpi_score2\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU        90         10\n 2 Finland      2022 WE/EU        87         13\n 3 New Zealand  2022 AP           87         13\n 4 Norway       2022 WE/EU        84         16\n 5 Singapore    2022 AP           83         17\n 6 Sweden       2022 WE/EU        83         17\n 7 Switzerland  2022 WE/EU        82         18\n 8 Netherlands  2022 WE/EU        80         20\n 9 Germany      2022 WE/EU        79         21\n10 Ireland      2022 WE/EU        77         23\n# ℹ 171 more rows\n\n\n\n\n2.5.4 Recodificar con case_when()\nLa función case_when() del paquete tidyverse en R sirve para recodificar datos y crear nuevas variables o modificar variables existentes basándose en múltiples condiciones.\nPermite evaluar varias condiciones utilizando una sintaxis similar a una instrucción “if-else”. Esta función es particularmente útil cuando necesitamos recodificar una variable en varias categorías o cuando tenemos múltiples condiciones a evaluar.\nSe coloca primero la condición (fórmula) seguido del símbolo ~ (alt+126) y la etiqueta.\nAl final se coloca TRUE, lo que indica todos aquellos casos que no cumplen con las condiciones anteriores.\n\n\nsummary(data_final$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  10.00   45.00   60.50   57.02   70.25   88.00       1 \n\n\n\ndata_final&lt;-data_final |&gt; \n  drop_na(cpi_score2)\nsummary(data_final$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.00   45.00   60.50   57.02   70.25   88.00 \n\n\nPodemos realizar:\n\ndata_final  |&gt;   \n  mutate(corrupcion=case_when(cpi_score2&lt;30~\"Bajo\", \n                              cpi_score2&lt;60~\"Medio\", \n                              cpi_score2&lt;=100~\"Alto\")) \n\n# A tibble: 180 × 6\n   country      year region cpi_score cpi_score2 corrupcion\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;     \n 1 Denmark      2022 WE/EU         90         10 Bajo      \n 2 Finland      2022 WE/EU         87         13 Bajo      \n 3 New Zealand  2022 AP            87         13 Bajo      \n 4 Norway       2022 WE/EU         84         16 Bajo      \n 5 Singapore    2022 AP            83         17 Bajo      \n 6 Sweden       2022 WE/EU         83         17 Bajo      \n 7 Switzerland  2022 WE/EU         82         18 Bajo      \n 8 Netherlands  2022 WE/EU         80         20 Bajo      \n 9 Germany      2022 WE/EU         79         21 Bajo      \n10 Ireland      2022 WE/EU         77         23 Bajo      \n# ℹ 170 more rows",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html#funciones-complementarias",
    "href": "s2_descriptivo.html#funciones-complementarias",
    "title": "2  Manipulación de tablas",
    "section": "2.5 Funciones complementarias",
    "text": "2.5 Funciones complementarias\n\n2.5.1 Agrupando con group_by()\nSe utiliza para dividir un conjunto de datos en grupos según valores de una o más variables (normalmente de tipo categórica). Una vez que los datos están agrupados, es posible realizar operaciones específicas dentro de cada grupo.\n\ndata |&gt;   \n  group_by(year) |&gt; \n  summarise(Media=mean(cpi_score, na.rm = T)) \n\n# A tibble: 6 × 2\n   year Media\n  &lt;dbl&gt; &lt;dbl&gt;\n1  2017  43.1\n2  2018  43.1\n3  2019  43.2\n4  2020  43.3\n5  2021  43.3\n6  2022  43.0\n\n\n\n\n2.5.2 Contar con count()\nFacilita el conteo de observaciones dentro de categorías específicas de una o más variables en un dataframe. Esta función agrupa el conjunto de datos por las variables especificadas y luego calcula el número de observaciones dentro de cada categoría, retornando un nuevo dataframe con las categorías y sus respectivos conteos. Es una herramienta esencial para obtener resúmenes rápidos y frecuencias de variables categóricas en datos estructurados.\n\ndata_final |&gt;   \n  count(region) |&gt;  \n  arrange(desc(n))  \n\n# A tibble: 6 × 2\n  region     n\n  &lt;chr&gt;  &lt;int&gt;\n1 SSA       49\n2 AME       32\n3 AP        32\n4 WE/EU     31\n5 ECA       19\n6 MENA      18\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn la última línea de código, indicamos a R que ordene los datos de acuerdo a la variable ‘n’, la cual fue definida en la línea de código precedente. Es importante recordar que la ejecución de acciones o funciones en R se realiza de manera secuencial y acumulativa.\n\n\n\n\n2.5.3 Renombrar con rename()\nPermite cambiar los nombres de las columnas de un dataframe. Para ello, se especifica el nuevo nombre deseado y el nombre actual de la columna. Esta función es útil cuando se necesita ajustar o estandarizar los nombres de las columnas en un conjunto de datos, facilitando así análisis posteriores y asegurando la claridad y consistencia en la manipulación de los datos.\nPrimero debes escribir el nuevo nombre y luego el nombre original de la variable.\n\ndata_final |&gt;   \n  rename(zona=region)   # Renombro la columna \"region\" (nombre original) como \"zona\" (nombre nuevo)\n\n# A tibble: 181 × 5\n   country      year zona  cpi_score cpi_score2\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU        90         10\n 2 Finland      2022 WE/EU        87         13\n 3 New Zealand  2022 AP           87         13\n 4 Norway       2022 WE/EU        84         16\n 5 Singapore    2022 AP           83         17\n 6 Sweden       2022 WE/EU        83         17\n 7 Switzerland  2022 WE/EU        82         18\n 8 Netherlands  2022 WE/EU        80         20\n 9 Germany      2022 WE/EU        79         21\n10 Ireland      2022 WE/EU        77         23\n# ℹ 171 more rows\n\n\n\n\n2.5.4 Recodificar con case_when()\nLa función case_when() del paquete tidyverse en R sirve para recodificar datos y crear nuevas variables o modificar variables existentes basándose en múltiples condiciones.\nPermite evaluar varias condiciones utilizando una sintaxis similar a una instrucción “if-else”. Esta función es particularmente útil cuando necesitamos recodificar una variable en varias categorías o cuando tenemos múltiples condiciones a evaluar.\nSe coloca primero la condición (fórmula) seguido del símbolo ~ (alt+126) y la etiqueta.\nAl final se coloca TRUE, lo que indica todos aquellos casos que no cumplen con las condiciones anteriores.\n\n\nsummary(data_final$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  10.00   45.00   60.50   57.02   70.25   88.00       1 \n\n\n\ndata_final&lt;-data_final |&gt; \n  drop_na(cpi_score2)\nsummary(data_final$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.00   45.00   60.50   57.02   70.25   88.00 \n\n\nPodemos realizar:\n\ndata_final  |&gt;   \n  mutate(corrupcion=case_when(cpi_score2&lt;30~\"Bajo\", \n                              cpi_score2&lt;60~\"Medio\", \n                              cpi_score2&lt;=100~\"Alto\")) \n\n# A tibble: 180 × 6\n   country      year region cpi_score cpi_score2 corrupcion\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;     \n 1 Denmark      2022 WE/EU         90         10 Bajo      \n 2 Finland      2022 WE/EU         87         13 Bajo      \n 3 New Zealand  2022 AP            87         13 Bajo      \n 4 Norway       2022 WE/EU         84         16 Bajo      \n 5 Singapore    2022 AP            83         17 Bajo      \n 6 Sweden       2022 WE/EU         83         17 Bajo      \n 7 Switzerland  2022 WE/EU         82         18 Bajo      \n 8 Netherlands  2022 WE/EU         80         20 Bajo      \n 9 Germany      2022 WE/EU         79         21 Bajo      \n10 Ireland      2022 WE/EU         77         23 Bajo      \n# ℹ 170 more rows",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s1_intro.html#ficha-resumen-cheat-sheet",
    "href": "s1_intro.html#ficha-resumen-cheat-sheet",
    "title": "1  Fundamentos de programación con R",
    "section": "1.6 Ficha resumen (Cheat Sheet)",
    "text": "1.6 Ficha resumen (Cheat Sheet)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Fundamentos de programación con R</span>"
    ]
  },
  {
    "objectID": "s2_descriptivo.html#ficha-resumen-cheat-sheet",
    "href": "s2_descriptivo.html#ficha-resumen-cheat-sheet",
    "title": "2  Manipulación de tablas",
    "section": "2.6 Ficha resumen (Cheat Sheet)",
    "text": "2.6 Ficha resumen (Cheat Sheet)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s3_descriptiva.html",
    "href": "s3_descriptiva.html",
    "title": "3  Estadística descriptiva",
    "section": "",
    "text": "3.1 Objetivos de la sesión",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "s3_descriptiva.html#objetivos-de-la-sesión",
    "href": "s3_descriptiva.html#objetivos-de-la-sesión",
    "title": "3  Estadística descriptiva",
    "section": "",
    "text": "Tras familiarizarnos con los principios básicos de la programación en R y la manipulación de sus elementos clave, nos centraremos en examinar a fondo una base de datos. Al concluir esta sesión, el estudiante dominará las técnicas y métodos estadísticos esenciales para sintetizar y destacar las características principales de un conjunto de datos.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "s3_descriptiva.html#presentación",
    "href": "s3_descriptiva.html#presentación",
    "title": "3  Estadística descriptiva",
    "section": "3.2 Presentación",
    "text": "3.2 Presentación",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "s3_descriptiva.html#problema-de-investigación-y-data",
    "href": "s3_descriptiva.html#problema-de-investigación-y-data",
    "title": "3  Estadística descriptiva",
    "section": "3.3 Problema de investigación y data",
    "text": "3.3 Problema de investigación y data\nDisponemos de una base de datos que incluye una variedad de indicadores e índices para 95 países alrededor del mundo. Los datos abarcan:\n-País\n-Continente\n-Región\n-Índice\n-Índice de Lavado de Activos\n-Matrícula\n-PBI per cápita\n-Pobreza Urbano\n-Gasto en educación\n-Índice de Percepción de la Corrupción\n-Estado de derecho\n-Índice de Democracia\n-Categoría del Índice de Democracia\n-Índice de Crimen Organizado\n\nlibrary(tidyverse)\nlibrary(readxl)\ndata&lt;-read_xlsx(\"data/AML.xlsx\")\n\nVeamos la data rápidamente:\n\nhead(data)\n\n# A tibble: 6 × 14\n  Pais       Continent Region AML_Index Matricula  PBIPC Pobreza URBANO gastoedu\n  &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 Afghanist… Asia      South… No se de…      50.1   552.    54.5   26       4.06\n2 Albania    Europe    Centr… 4.75           86.6  5224.    14.3   62.1     2.47\n3 Angola     Africa    Centr… 7.03           11.3  3437.    36.6   66.8     3.42\n4 Argentina  Americas  South… No se de…      90.8 11688.    25.7   92.1     5.46\n5 Armenia    Asia      Centr… 4.72           87.7  4212.    32     63.3     2.71\n6 Austria    Europe    Weste… 4.099999…      87   51230.     3     58.7     5.5 \n# ℹ 5 more variables: CPI_Index &lt;dbl&gt;, Rule_of_Law &lt;dbl&gt;,\n#   Democracy_Index &lt;dbl&gt;, Democracy_Index_cat &lt;chr&gt;,\n#   Organized_Crime_Index &lt;dbl&gt;",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "s3_descriptiva.html#estadísticos-descriptivos",
    "href": "s3_descriptiva.html#estadísticos-descriptivos",
    "title": "3  Estadística descriptiva",
    "section": "3.4 Estadísticos descriptivos",
    "text": "3.4 Estadísticos descriptivos\nAdemás de memorizar las fórmulas, que sin duda son esenciales, te invito a que, al abordar una base de datos, consideres las siguientes preguntas esenciales al momento de describir una variable:\n\n¿Cuál sería el mejor representante de estos datos?\n¿Cuánto varían estos datos?\n\n\n3.4.1 ¿Cuál sería el mejor representante de estos datos?\nEl “mejor representante” de un conjunto de datos se refiere a la medida de tendencia central que mejor resume la información de dicho conjunto. Las opciones principales incluyen la media, la mediana y la moda:\n\n3.4.1.1 La media\nLa media es el promedio aritmético y proporciona un centro de gravedad de los datos. Es útil cuando los datos son simétricos y sin valores atípicos significativos. Recordemos que la función a utilizar es mean().\nPor ejemplo, si deseamos la media de PBI per cápita, Pobreza y el Gasto de Educación:\n\nmean(data$PBIPC)\n\n[1] 11823.83\n\nmean(data$Pobreza)\n\n[1] 27.92947\n\nmean(data$gastoedu)\n\n[1] 4.427158\n\n\nSi lo queremos ver de forma comparativa y en una sola línea de código podemos utilizar tidyverse:\n\ndata |&gt; \n  summarise(mean(PBIPC), mean(Pobreza), mean(gastoedu))\n\n# A tibble: 1 × 3\n  `mean(PBIPC)` `mean(Pobreza)` `mean(gastoedu)`\n          &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;\n1        11824.            27.9             4.43\n\n\n\n\n3.4.1.2 La mediana\nLa mediana es el valor que se encuentra en el punto medio de un conjunto de datos ordenado. Resulta especialmente informativa en distribuciones sesgadas, ya que no es tan susceptible a los valores extremos como la media. Usamos la función median().\nSigamos con las variables PBI per cápita, Pobreza y el Gasto de Educación:\n\nmedian(data$PBIPC)\n\n[1] 4900.76\n\nmedian(data$Pobreza)\n\n[1] 23.4\n\nmedian(data$gastoedu)\n\n[1] 4.56\n\n\nSi lo queremos ver de forma comparativa podemos utilizar tidyverse:\n\ndata |&gt; \n  summarise(median(PBIPC), median(Pobreza), median(gastoedu))\n\n# A tibble: 1 × 3\n  `median(PBIPC)` `median(Pobreza)` `median(gastoedu)`\n            &lt;dbl&gt;             &lt;dbl&gt;              &lt;dbl&gt;\n1           4901.              23.4               4.56\n\n\n\n\n3.4.1.3 La moda\nLa moda es el valor o valores que aparecen con mayor frecuencia. Es la única medida de tendencia central aplicable a datos nominales. Para este caso en específico, podemos utilizar la función table() o también la función count() dentro de un fraseo de tidyverse:\n\ntable(data$Continent)\n\n\n  Africa Americas     Asia   Europe  Oceania \n      29       20       17       26        3 \n\n\nO también:\n\ndata |&gt; \n  count(Continent)\n\n# A tibble: 5 × 2\n  Continent     n\n  &lt;chr&gt;     &lt;int&gt;\n1 Africa       29\n2 Americas     20\n3 Asia         17\n4 Europe       26\n5 Oceania       3\n\n\nPodemos añadir también una columna de porcentaje usando la función mutate():\n\ndata |&gt; \n  count(Continent) |&gt; \n  mutate(Porcentaje=n/sum(n)*100)\n\n# A tibble: 5 × 3\n  Continent     n Porcentaje\n  &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 Africa       29      30.5 \n2 Americas     20      21.1 \n3 Asia         17      17.9 \n4 Europe       26      27.4 \n5 Oceania       3       3.16\n\n\n\n\n\n3.4.2 ¿Cuánto varían estos datos?\nLa variación de los datos se refiere al grado en que los valores del conjunto de datos difieren de una medida de tendencia central. Las medidas de variabilidad incluyen el rango, la varianza, la desviación estándar y el coeficiente de variación:\n\n3.4.2.1 El rango\nEl rango ofrece una visión general muy básica de la variabilidad, indicando la diferencia entre los valores más alto y más bajo.\nEs una medida muy sencilla de calcular y proporciona una idea general de la variabilidad de los datos. Sin embargo, no toma en cuenta la distribución de los datos en el conjunto, lo que puede hacer que la medida sea menos informativa en ciertos casos.\nPara ver el valor mínimo y máximo:\n\nrange(data$PBIPC)\n\n[1]   293.96 82708.51\n\nrange(data$Pobreza)\n\n[1]  2.6 72.3\n\nrange(data$gastoedu)\n\n[1] 1.11 7.67\n\n\nPara ver el rango:\n\nmax(data$PBIPC)-min(data$PBIPC)\n\n[1] 82414.55\n\nmax(data$Pobreza)-min(data$Pobreza)\n\n[1] 69.7\n\nmax(data$gastoedu)-min(data$gastoedu)\n\n[1] 6.56\n\n\n\n\n3.4.2.2 La varianza y la desviación estándar\nLa varianza es una medida de dispersión que indica qué tan dispersos están los datos con respecto a su media.\nSe calcula como el promedio de los cuadrados de las diferencias entre cada valor y la media del conjunto. En otras palabras, indica cuán alejados están los valores individuales de la media. La varianza proporciona una idea de la variabilidad o volatilidad de los datos, siendo un indicador clave de cuánto tienden a variar los valores respecto a la media.\n\\[s^2 = \\frac{1}{N-1}\\sum_{i=1}^{N}(x_i - \\mu)^2\\]\n\n\n\n\n\n\nAdvertencia\n\n\n\nSe utiliza n−1 para calcular la varianza en una muestra como un ajuste para corregir el sesgo en la estimación de la varianza poblacional, garantizando una estimación más precisa. Esto lo entenderemos mejor cuando veamos inferencia.\n\n\nLa varianza proporciona una idea de la dispersión general de los datos, pero debido a que las diferencias se elevan al cuadrado, la varianza no está en las mismas unidades que los datos originales, lo que puede dificultar su interpretación directa.\nUsamos la función var():\n\nvar(data$PBIPC)\n\n[1] 276058288\n\nvar(data$Pobreza)\n\n[1] 283.7038\n\nvar(data$gastoedu)\n\n[1] 1.859397\n\n\nPor otro lado, la desviación estándar, al tomar la raíz cuadrada de la varianza vuelve a las unidades originales de los datos, lo que facilita su comprensión e interpretación. La desviación estándar indica cuánto, en promedio, se desvían los valores de la media del conjunto de datos. Lo calculamos con la función sd().\nUn valor bajo de desviación estándar indica que los datos están agrupados cerca de la media, mientras que un valor alto señala que los datos están más dispersos.\nSirve mucho cuando comparamos dos variables que están en las mismas unidades, como por ejemplo:\n\ndata |&gt; filter(Continent==\"Africa\") |&gt; summarise(sd(PBIPC))\n\n# A tibble: 1 × 1\n  `sd(PBIPC)`\n        &lt;dbl&gt;\n1       3509.\n\ndata |&gt; filter(Continent==\"Europe\") |&gt; summarise(sd(PBIPC))\n\n# A tibble: 1 × 1\n  `sd(PBIPC)`\n        &lt;dbl&gt;\n1      20462.\n\n\nEn este caso podemos evidenciar que en el caso de los países de África existe más dispersión (3508.5 dólares de distancia de la media en promedio) que en Europa (20461.5 dólares de distancia de la media en promedio).\n\n\n\n\n\n\nAdvertencia\n\n\n\nA pesar que en la descripción de una variable se suele preferir utilizar la desviación estándar por las características mencionadas, la varianza tiene propiedades matemáticas importantes que la hacen el centro de diversas técnicas inferenciales que veremos más adelante.\n\n\n\n\n3.4.2.3 El coeficiente de variación\nEl coeficiente de variación (CV) es una medida estadística que describe la relación entre la desviación estándar (σ) y la media (μ) de un conjunto de datos, expresada como un porcentaje.\nDe forma sencilla, el coeficiente de variación indica cuán grande es la variabilidad de los datos en comparación con la media del conjunto.\n\\[CV = \\left( \\frac{s}{\\mu} \\right) \\times 100\\%\\]\nEl coeficiente de variación es particularmente útil porque proporciona una medida de variabilidad relativa independiente de la escala de los datos, lo cual permite comparar la dispersión de dos o más conjuntos de datos que podrían tener diferentes unidades de medida o medias muy distintas (lo que podría distorsionar el análisis).\nSi bien NO HAY UN CONSENSO en los umbrales para la interpretación, para este curso, utilizaremos los siguientes criterios:\n\n]0%-10%]: Variabilidad baja\n]10%-20%]: Variabilidad media\nMayor a 20%: Variabilidad alta\n\nPor ejemplo, en nuestro caso, ¿qué tanta variabilidad posee PBI per cápita, Pobreza y el Gasto de Educación? ¿Cuál presenta la mayor variabilidad?\n\ncv_PBIPC &lt;- sd(data$PBIPC) / mean(data$PBIPC) * 100\ncv_Pobreza &lt;- sd(data$Pobreza) / mean(data$Pobreza) * 100\ncv_gastoedu &lt;- sd(data$gastoedu) / mean(data$gastoedu) * 100\n\n\ncv_PBIPC\n\n[1] 140.5214\n\ncv_Pobreza\n\n[1] 60.30729\n\ncv_gastoedu\n\n[1] 30.80073\n\n\nCon esta medida estandarizada es mucho mejor realizar la comparación y responder a la pregunta planteada.\n\n\n\n3.4.3 Comparación en grupos\nEs común querer explorar cómo los descriptivos estadísticos varían entre diferentes grupos o categorías dentro de un conjunto de datos. Para facilitar este tipo de análisis, el paquete dplyr de R ofrece la función group_by(), que permite agrupar los datos por una o más variables categóricas y luego calcular estadísticas descriptivas para cada grupo. Esta práctica es especialmente útil para entender las diferencias y similitudes entre grupos, ayudando en la toma de decisiones basada en datos y en la formulación de hipótesis para análisis más detallados.\n\ndata |&gt; \n  group_by(Continent) |&gt; \n  summarise(cv_PBIPC=sd(PBIPC) / mean(PBIPC) * 100,\n            cv_Pobreza = sd(Pobreza) / mean(Pobreza) * 100,\n            cv_gastoedu = sd(gastoedu) / mean(gastoedu) * 100)\n\n# A tibble: 5 × 4\n  Continent cv_PBIPC cv_Pobreza cv_gastoedu\n  &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n1 Africa       159.        36.4        35.6\n2 Americas     121.        48.0        25.5\n3 Asia          81.3       67.3        32.7\n4 Europe        70.1       47.4        24.2\n5 Oceania       39.2       24.2        35.0",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "s3_descriptiva.html#visualización-de-datos",
    "href": "s3_descriptiva.html#visualización-de-datos",
    "title": "3  Estadística descriptiva",
    "section": "3.5 Visualización de datos",
    "text": "3.5 Visualización de datos\nDependiendo del tipo de variables que se analizan, las técnicas y herramientas de visualización varían. A continuación, se describen las aproximaciones recomendadas para visualizar datos, diferenciando entre variables categóricas y numéricas.\n\n3.5.1 Cómo funciona ggplot2\n\nggplot2 es un popular paquete de visualización de datos para el lenguaje de programación R, basado en los principios de la “Gramática de Gráficos”. Esta filosofía de diseño permite a los usuarios construir gráficos complejos y estéticamente agradables a partir de componentes básicos de forma intuitiva y flexible. El núcleo de ggplot2 radica en su sistema de capas, donde cada gráfico se construye agregando capas que pueden incluir, entre otros, los datos, las estéticas (como color, forma y tamaño), los objetos geométricos (como puntos, líneas y barras), las escalas, y las anotaciones. Este enfoque modular no solo facilita la personalización y optimización de los gráficos sino que también promueve una estructura de código clara y comprensible.\nVamos a hacer un ejemplo paso a paso:\n\nDatos: Conjunto de datos a visualizar\n\nNuestra primera capa siempre va a ser la data. Sobre esta iniciamos la función ggplot y corroboramos que tenemos un lienzo en blanco.\n\ndata |&gt; \n  ggplot()\n\n\n\n\n\n\n\n\n\nEstéticas: Diseño básico del gráfico (Aesthetics)\n\nMapeo de variables a propiedades visuales como color, forma o tamaño, definidas con aes().\nA diferencia del lienzo en blanco, ya contamos con un diseño. En este caso, hemos indicado al R que el eje X será la variable Pobreza.\n\ndata |&gt; \n  ggplot()+\n  aes(x=Pobreza)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEn ggplot2, las capas de un gráfico se van adicionando secuencialmente utilizando el operador +.\n\n\n\nGeometrías (Geoms) Representaciones gráficas de los datos, como puntos, líneas o barras (geom_point(), geom_line(), geom_bar(), etc.).\n\nEn nuestro ejemplo, podemos agregar la geometría de histograma:\n\ndata |&gt; \n  ggplot()+\n  aes(x=Pobreza)+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn el paquete {ggplot2} existen 30 geometrías disponibles. Puedes ver el detalle de estos en la documentación del paquete.\n\n\nEsta estructura de capas hace que ggplot2 sea extremadamente poderoso para explorar y presentar datos de manera efectiva, permitiendo a los usuarios desde principiantes hasta expertos crear visualizaciones de datos complejas y personalizadas con relativa facilidad.\n\nFacetas, Estadísticas, Coordenadas y Temas\n\nLas demás capas del ggplot lo vamos a ir viendo a medida que vayamos avanzando en el curso. No obstante, te sugiero ver el siguiente ppt que profundiza y ejemplifica cada una de las capas restantes.\nSi deseas adelantar un poco, puedes mirar esta presentación, donde exploro el detalle de las capas restantes.\nTambién te sugiero ver este video de soporte\n\n\n\n3.5.2 Para variables categóricas\n\n3.5.2.1 Gráfico de barras\nEn un gráfico de barras vertical,las categorías se representan en el eje horizontal y la frecuencia o cantidad en el eje vertical.\nEl gráfico de barras es una herramienta útil para comparar la frecuencia o cantidad de diferentes categorías o variables en un conjunto de datos.\nUtilizamos la función geom_bar(). El resultado es que la función ha CONTADO la frecuencia de cada categoría de DemocracyIndexCat\n\ndata |&gt;                # Data\n  ggplot() +           # Iniciamos la construcción del gráfico con ggplot \n  aes(x = Democracy_Index_cat) + # Establecemos la variable como el eje x\n  geom_bar()           # Creamos un gráfico de barras basado en el conteo de 'continent'\n\n\n\n\n\n\n\n\nEn algunas ocasiones ya contamos con el conteo realizado y sólo deseamos el gráfico. Para ello utilizamos el ARGUMENTO stat=“identity”.\nUn caso como el siguiente:\n\ndata |&gt;  \n  count(Democracy_Index_cat)\n\n# A tibble: 5 × 2\n  Democracy_Index_cat     n\n  &lt;chr&gt;               &lt;int&gt;\n1 Authoritarian          24\n2 Flawed democracy       32\n3 Full democracy         11\n4 Hybrid regime          23\n5 &lt;NA&gt;                    5\n\n\nEn estos casos utilizamos la función:\n\ndata |&gt;  \n  count(Democracy_Index_cat) |&gt; \n  ggplot() +           \n  aes(y = n, x=Democracy_Index_cat) + #En este caso le he tenido que especificar tanto x como y!\n  geom_bar(stat=\"identity\")          \n\n\n\n\n\n\n\n\nAgregando etiquetas de los datos y nombres de los ejes:\n\ndata |&gt;  \n  count(Democracy_Index_cat) |&gt; \n  ggplot() +           \n  aes(y = n, x=Democracy_Index_cat) + #En este caso le he tenido que especificar tanto x como y!\n  geom_bar(stat=\"identity\")+\n  geom_text(aes(label=n, vjust=-1, size=3))+\n  labs(x=\"Tipo de régimen\", y=\"Frecuencia\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nAunque los gráficos de pie son ampliamente reconocidos y frecuentemente utilizados para mostrar proporciones de un todo, en la práctica suelen ser menos efectivos que los gráficos de barras. Esto se debe a que los gráficos de barras ofrecen una comparación más clara y precisa entre categorías, facilitando la interpretación de las diferencias en magnitud.\n\n\n\n\n\n3.5.3 Para variables numéricas\n\n3.5.3.1 Boxplot\n\nEs utilizado para representar la distribución de un conjunto de datos numéricos a través de sus cuartiles.\nEl gráfico consiste en una caja que representa el rango intercuartil (IQR),es decir, la diferencia entre el tercer cuartil (Q3) y el primer cuartil(Q1).\nDentro de la caja,se dibuja una línea que representa la mediana.\nLos bigotes,que se extienden desde la caja, indican el rango de los datos que se encuentran dentro de un cierto múltiplo del IQR, generalmente 1.5 veces el IQR.\n\ndata |&gt; \n  ggplot() + \n  aes(y = PBIPC) + # Establecemos 'lifeExp' en el eje x\n  geom_boxplot()\n\n\n\n\n\n\n\n\nLos valores que están por encima o por debajo de los bigotes se representan como puntos o asteriscos, que se conocen como valores atípicos.\nEl boxplot es útil para identificar valores atípicos y para comparar la distribución de varios conjuntos de datos en un solo gráfico. También permite visualizar la simetría o asimetría de la distribución y la presencia de sesgo.\nPuedes probar este video sugerido:\n\nTambién puedes solicitar boxplot por grupos:\n\ndata |&gt; \n  ggplot() + \n  aes(y = PBIPC, colour=Continent) + # Establecemos 'lifeExp' en el eje x\n  geom_boxplot()\n\n\n\n\n\n\n\n\n¿qué nos dice este gráfico?\n\n\n3.5.3.2 Histograma\nUn histograma es un tipo de gráfico utilizado en estadísticas para representar la distribución de un conjunto de datos numéricos mediante barras. Cada barra en un histograma representa la frecuencia (número de veces que ocurren) de datos dentro de un intervalo o “bin” específico.\nLos bins dividen el espectro completo de los datos en series de intervalos consecutivos, y son todos de igual tamaño. La altura de cada barra muestra cuántos datos caen dentro de cada intervalo.\n\ndata |&gt; \n  ggplot() + \n  aes(x=PBIPC) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nLos histogramas permiten observar cómo se distribuyen los datos, revelando si están equilibradamente repartidos o inclinados hacia un extremo. Una distribución es simétrica cuando las mitades a ambos lados de la media son imágenes espejo.\nSi está sesgada hacia la derecha, significa que hay una acumulación de datos hacia el lado izquierdo del gráfico, con una cola que se extiende hacia la derecha. Como en el caso del gráfico de líneas arriba.\nPor otro lado, un sesgo hacia la izquierda indica una concentración de datos hacia la derecha, con una cola que se alarga hacia la izquierda. Los histogramas también muestran si los datos se agrupan en torno a varios valores centrales, evidenciado por la presencia de varios picos o “modas”.\nAsí como nuestros gráficos anteriores, podemos personalizar mucho más nuestro gráfico:\n\ndata |&gt; \n  ggplot() + \n  aes(x=PBIPC) + \n  geom_histogram()+\n  geom_vline(xintercept = mean(data$PBIPC), color = \"red\")+\n  geom_vline(xintercept = median(data$PBIPC), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n3.5.3.3 Gráfico de línea\nEl gráfico de líneas es una herramienta de visualización de datos que conecta puntos de datos individuales con líneas, mostrando tendencias o cambios en una variable numérica a lo largo del tiempo o de otra variable numérica. Sirve principalmente para visualizar la evolución de una o varias cantidades, permitiendo identificar patrones, tendencias, picos, y caídas en los datos a lo largo de un período o rango específico.\n\nlibrary(readxl)\nCPI&lt;-read_xlsx(\"data/CPI.xlsx\")\n\nCómo evolucionó Perú en el CPI score desde el 2017?\n\nCPI |&gt; \n  filter(country==\"Peru\"|country==\"Bolivia\" |country==\"Italy\") |&gt; \n  ggplot() +\n  aes(x=year, y=cpi_score, color=country)+\n  geom_line()+\n  geom_point()+\n  ylim(0, 80)+\n  geom_text(aes(label=round(cpi_score, 1)), \n            vjust=-0.5,                   \n            hjust=1.2)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Estadística descriptiva</span>"
    ]
  },
  {
    "objectID": "s2_manipulacion.html",
    "href": "s2_manipulacion.html",
    "title": "2  Manipulación de tablas",
    "section": "",
    "text": "2.1 Objetivos de la sesión",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_manipulacion.html#objetivos-de-la-sesión",
    "href": "s2_manipulacion.html#objetivos-de-la-sesión",
    "title": "2  Manipulación de tablas",
    "section": "",
    "text": "Al final de esta sesión, el estudiante será capaz de manipular un dataframe a fin de editarlo de acuerdo a su necesidad utilizando algunos verbos básicos del paquete dplyr. También podrá solicitar algunos de los principales estadísticos descriptivos de tendencia central.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_manipulacion.html#presentación",
    "href": "s2_manipulacion.html#presentación",
    "title": "2  Manipulación de tablas",
    "section": "2.2 Presentación",
    "text": "2.2 Presentación",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_manipulacion.html#introducción-al-tidyverse",
    "href": "s2_manipulacion.html#introducción-al-tidyverse",
    "title": "2  Manipulación de tablas",
    "section": "2.3 Introducción al Tidyverse",
    "text": "2.3 Introducción al Tidyverse\nEl tidyverse es una colección de paquetes de R diseñados para la ciencia de datos que comparten una filosofía subyacente y son interoperables, facilitando la importación, manipulación, exploración y visualización de datos.\nTe sugiero ver este video introductorio sobre el Tidyverse:\n\nAbrimos la librería tidyverse:\n\nlibrary(tidyverse)\nlibrary(rio)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_manipulacion.html#manipulación-de-datos-con-dplyr",
    "href": "s2_manipulacion.html#manipulación-de-datos-con-dplyr",
    "title": "2  Manipulación de tablas",
    "section": "2.4 Manipulación de datos con dplyr",
    "text": "2.4 Manipulación de datos con dplyr\ndplyr es un paquete del Tidyverse que sirve para manipular tablas y transformarlas. Tiene una amplia gama de verbos con los cuales podemos realizar las tareas más recurrentes de la manipulación de datos.\n\n\n2.4.1 Problema de investigación y data\n\nEl Índice de Percepción de la Corrupción (CPI, por sus siglas en inglés) es una herramienta global que clasifica a los países según la percepción de corrupción en el sector público, basándose en evaluaciones de expertos y encuestas de negocios. La escala va de 0 (muy corrupto) a 100 (muy limpio), y sirve para comparar la situación de corrupción entre diferentes naciones. Es publicado anualmente por Transparency International, una organización no gubernamental dedicada a combatir la corrupción global.\nExaminemos la base original. Vamos a editar la tabla con diversos verbos de dplyr.\nAbrir archivo\nAbrimos el archivo con el paquete `rio``:\n\nlibrary(rio)\ndata_con_rio&lt;-import(\"data/CPI.xlsx\")\n\nTen en cuenta que en el R también existen otros paquetes como readr, haven o readxl que también te permiten abrir archivos de distintos formatos.\nPor ejemplo, podríamos abrir este archivo con la función read_xlsx():\n\nlibrary(readxl)\ndata&lt;-read_xlsx(\"data/CPI.xlsx\")\n\nPodemos ver las datas (y las diferencias que trae abrirlas con uno u otro paquete):\n\n#data_con_rio\nclass(data_con_rio)\n\n[1] \"data.frame\"\n\n\n\ndata\n\n# A tibble: 1,086 × 5\n   country               year iso3  region cpi_score\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Afghanistan           2022 AFG   AP            24\n 2 Albania               2022 ALB   ECA           36\n 3 United Arab Emirates  2022 ARE   MENA          67\n 4 Angola                2022 AGO   SSA           33\n 5 Argentina             2022 ARG   AME           38\n 6 Armenia               2022 ARM   ECA           46\n 7 Australia             2022 AUS   AP            75\n 8 Austria               2022 AUT   WE/EU         71\n 9 Azerbaijan            2022 AZE   ECA           23\n10 Bahamas               2022 BHS   AME           64\n# ℹ 1,076 more rows\n\nclass(data)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n\n\n\n\nNota\n\n\n\nUn tibble es una versión moderna del dataframe en R, parte del tidyverse, diseñado para facilitar el trabajo con datos tabulares.\n\n\nExploración del dataset y configuración de variables\nVemos la estructura rápidamente:\n\nstr(data)\n\ntibble [1,086 × 5] (S3: tbl_df/tbl/data.frame)\n $ country  : chr [1:1086] \"Afghanistan\" \"Albania\" \"United Arab Emirates\" \"Angola\" ...\n $ year     : num [1:1086] 2022 2022 2022 2022 2022 ...\n $ iso3     : chr [1:1086] \"AFG\" \"ALB\" \"ARE\" \"AGO\" ...\n $ region   : chr [1:1086] \"AP\" \"ECA\" \"MENA\" \"SSA\" ...\n $ cpi_score: num [1:1086] 24 36 67 33 38 46 75 71 23 64 ...\n\n\nAl ejecutar names() sobre un conjunto de datos, se nos devuelve un vector con los nombres de todas las columnas en el orden en que aparecen.\n\nnames(data)\n\n[1] \"country\"   \"year\"      \"iso3\"      \"region\"    \"cpi_score\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nAntes de proseguir con el análisis descriptivo, es fundamental que comprendas claramente qué representan las filas y las columnas en tus datos.\n\n\nCorroboramos que el score del CPI esté adecuadamente configurado.\n\nclass(data$cpi_score)\n\n[1] \"numeric\"\n\n\nDe acuerdo, podemos proseguir.\n\n\n2.4.2 Select()\nLa función select() es utilizada para seleccionar o excluir columnas de un data frame o tibble en R. Va más allá de simplemente escoger columnas por nombre, ya que permite una amplia gama de criterios y operaciones.\nFuncionamiento básico:\n\nEntrada: Un data frame o tibble y un conjunto de nombres de columnas o criterios para seleccionar columnas.\nSalida: Un objeto de la misma clase que el de entrada (data frame o tibble) que contiene solo las columnas seleccionadas.\n\nVamos a seleccionar sólo ciertas columnas:\n\ndata1&lt;-data |&gt; \n  select(country, year, region, cpi_score)\ndata1\n\n# A tibble: 1,086 × 4\n   country               year region cpi_score\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Afghanistan           2022 AP            24\n 2 Albania               2022 ECA           36\n 3 United Arab Emirates  2022 MENA          67\n 4 Angola                2022 SSA           33\n 5 Argentina             2022 AME           38\n 6 Armenia               2022 ECA           46\n 7 Australia             2022 AP            75\n 8 Austria               2022 WE/EU         71\n 9 Azerbaijan            2022 ECA           23\n10 Bahamas               2022 AME           64\n# ℹ 1,076 more rows\n\n\nTener en cuenta que puedes:\n\nSeleccionar por nombre\nSeleccionar por el número de la columna\n(Des)seleccionar colocando un “-” antes del nombre/número de columna.\nSeleccionar un rango colocando por ejemplo 2:4 lo que significa “desde la columna 2 hasta la columna 4).\nPuedes combinar todas las anteriores y tener más de un criterio a la vez separándolo por coma.\n\n\n\n2.4.3 Filter()\nLa función filter() se utiliza para filtrar filas de un data frame o tibble en R en función de condiciones específicas, permitiendo crear un subconjunto de datos.\nAl crear subconjuntos nuestros datos de forma precisa, podemos focalizar nuestro análisis, mejorar la eficiencia computacional y obtener resultados más claros y relevantes.\nCaracterísticas principales:\n\nCondiciones múltiples: Puedes usar múltiples condiciones para filtrar tus datos. Estas se combinan utilizando operadores lógicos como & (y), | (o) y ! (no).\nUso de operadores de comparación: Los operadores estándar como ==, &gt;, &lt;, &gt;=, &lt;=, y != se utilizan para establecer condiciones.\nFunciones auxiliares: dplyr proporciona funciones como between(), que pueden ser útiles para establecer condiciones. Por ejemplo, between(x, 1, 10) es equivalente a x &gt;= 1 & x &lt;= 10.\n\nEn este caso vamos a seleccionar aquellos países cuya medición es del año 2022.\n\ndata2&lt;-data1 %&gt;%                   \n  filter(year==2022)\ndata2\n\n# A tibble: 181 × 4\n   country               year region cpi_score\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Afghanistan           2022 AP            24\n 2 Albania               2022 ECA           36\n 3 United Arab Emirates  2022 MENA          67\n 4 Angola                2022 SSA           33\n 5 Argentina             2022 AME           38\n 6 Armenia               2022 ECA           46\n 7 Australia             2022 AP            75\n 8 Austria               2022 WE/EU         71\n 9 Azerbaijan            2022 ECA           23\n10 Bahamas               2022 AME           64\n# ℹ 171 more rows\n\n\n\n\n2.4.4 Arrange()\nSe utiliza para ordenar (o reordenar) un data frame o tibble según una o más columnas.\nFuncionamiento básico:\n\nOrdenación simple: Si proporcionas una columna a arrange(), ordenará el data frame en función de esa columna en orden ascendente por defecto.\nOrdenación descendente: Si deseas ordenar en dirección descendente, puedes usar la función desc(). Por ejemplo: df |&gt; arrange(desc(edad)) ordenará el data frame por la columna “edad” en orden descendente.\nOrdenación múltiple: Puedes proporcionar múltiples columnas para ordenar, y arrange() las usará en el orden proporcionado para determinar el ordenamiento. Por ejemplo, si deseas ordenar primero por “grupo” y luego por “edad” dentro de cada grupo, usarías: df |&gt; arrange(grupo, edad).\n\n\ndata3&lt;-data2 |&gt;    \n  arrange(desc(cpi_score))\ndata3\n\n# A tibble: 181 × 4\n   country      year region cpi_score\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU         90\n 2 Finland      2022 WE/EU         87\n 3 New Zealand  2022 AP            87\n 4 Norway       2022 WE/EU         84\n 5 Singapore    2022 AP            83\n 6 Sweden       2022 WE/EU         83\n 7 Switzerland  2022 WE/EU         82\n 8 Netherlands  2022 WE/EU         80\n 9 Germany      2022 WE/EU         79\n10 Ireland      2022 WE/EU         77\n# ℹ 171 more rows\n\n\n\n\n2.4.5 Mutate()\nLa función mutate() está diseñada para crear o modificar columnas dentro de un data frame o tibble en R. Mientras que el data frame original se mantiene inalterado, mutate() devuelve una copia con las columnas especificadas añadidas o alteradas.\nEn este caso vamos a crear una variable cambiando la escala del score del CPI.\nEn la medida original 0 representaba alta corrupción y 100 escasa corrupción. Ahora, si realizamos la operación “100 - cpi_score”, los valores cercanos a 0 tendrán poca corrupción y los cercanos a 100 alta corrupción, siendo más intuitivo.\nEsta transformación puede ser útil para ajustar la interpretación de los datos a contextos donde es más intuitivo trabajar con escalas donde un número mayor indica mayor intensidad de un fenómeno (Corrupción, en este caso), dependiendo del análisis que se desea realizar.\n\ndata4&lt;-data3 |&gt;   \n  mutate(cpi_score2=100-cpi_score) \ndata4\n\n# A tibble: 181 × 5\n   country      year region cpi_score cpi_score2\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU         90         10\n 2 Finland      2022 WE/EU         87         13\n 3 New Zealand  2022 AP            87         13\n 4 Norway       2022 WE/EU         84         16\n 5 Singapore    2022 AP            83         17\n 6 Sweden       2022 WE/EU         83         17\n 7 Switzerland  2022 WE/EU         82         18\n 8 Netherlands  2022 WE/EU         80         20\n 9 Germany      2022 WE/EU         79         21\n10 Ireland      2022 WE/EU         77         23\n# ℹ 171 more rows\n\n\n\n\n2.4.6 Summarise()\nSe utiliza para crear resúmenes estadísticos de un data frame o tibble.\nDentro de los resúmenes puedes disponer de por ejemplo:\nMedidas de tendencia central: Estas funciones describen un valor central o típico dentro de un conjunto de datos.\n\nMedia: mean(x)\nMediana: median(x)\n\nCómo calcularíamos la media de forma directa (tradicional)?\n\nsummary(data4$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  10.00   45.00   60.50   57.02   70.25   88.00       1 \n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\n¿Qué significa NA´s? ¿Por qué se produce esto en una data como la de Corruption Perception Index?\n\n\nCómo lo calculamos con tidyverse?\n\ndata4 |&gt;   \n  summarise(mean(cpi_score2, na.rm = T))    \n\n# A tibble: 1 × 1\n  `mean(cpi_score2, na.rm = T)`\n                          &lt;dbl&gt;\n1                          57.0\n\n\n\n\n\n\n\n\nNota\n\n\n\nCuando aplicamos un summarise lo que nos devuelve es un valor o conjunto de valores. Por otro lado, el argumento na.rm = TRUE se utiliza para especificar que los valores perdidos (NA) deben ser ignorados en el cálculo. De esta forma, le indicamos a la función que proceda con la operación excluyendo dichos valores ausentes.\n\n\n\n\n2.4.7 Utilizando pipe: |&gt;\nProbablemente hayas observado que hemos creado un conjunto de datos para cada verbo utilizado, lo cual en situaciones reales resultaría excesivamente repetitivo. Haciendo una analogía con la escritura de un libro, sería como si estuviéramos limitados a usar únicamente oraciones, lo cual haría el proceso tedioso.\nEl operador |&gt; (pipe) en R, introducido en la versión 4.1, permite realizar operaciones en cadena, facilitando la secuencia de funciones y transformaciones en un flujo más legible y ordenado.\nEs evidente que, mediante el uso del operador pipe, podemos encadenar verbos de manera fluida y evitar la creación innecesaria de objetos, ya que este operador permite que el resultado a la izquierda se convierta automáticamente en el argumento de la función a la derecha.\n\ndata |&gt;\n  select(country, year, region, cpi_score) |&gt; \n  filter(year==2022) |&gt; \n  arrange(desc(cpi_score)) |&gt; \n  mutate(cpi_score2=100-cpi_score) |&gt; \n  summarise(mean(cpi_score2, na.rm=T))  \n\n# A tibble: 1 × 1\n  `mean(cpi_score2, na.rm = T)`\n                          &lt;dbl&gt;\n1                          57.0\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\n¿Qué sucede si a esta cadena de pipes le doy un nombre? ¿Cuál sería el objeto creado?\n\n\n\ndata_final&lt;-data |&gt;\n  select(country, year, region, cpi_score) |&gt; \n  filter(year==2022) |&gt;\n  arrange(desc(cpi_score)) |&gt;\n  mutate(cpi_score2=100-cpi_score)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_manipulacion.html#funciones-complementarias",
    "href": "s2_manipulacion.html#funciones-complementarias",
    "title": "2  Manipulación de tablas",
    "section": "2.5 Funciones complementarias",
    "text": "2.5 Funciones complementarias\n\n2.5.1 Agrupando con group_by()\nSe utiliza para dividir un conjunto de datos en grupos según valores de una o más variables (normalmente de tipo categórica). Una vez que los datos están agrupados, es posible realizar operaciones específicas dentro de cada grupo.\n\ndata |&gt;   \n  group_by(year) |&gt; \n  summarise(Media=mean(cpi_score, na.rm = T)) \n\n# A tibble: 6 × 2\n   year Media\n  &lt;dbl&gt; &lt;dbl&gt;\n1  2017  43.1\n2  2018  43.1\n3  2019  43.2\n4  2020  43.3\n5  2021  43.3\n6  2022  43.0\n\n\n\n\n2.5.2 Contar con count()\nFacilita el conteo de observaciones dentro de categorías específicas de una o más variables en un dataframe. Esta función agrupa el conjunto de datos por las variables especificadas y luego calcula el número de observaciones dentro de cada categoría, retornando un nuevo dataframe con las categorías y sus respectivos conteos. Es una herramienta esencial para obtener resúmenes rápidos y frecuencias de variables categóricas en datos estructurados.\n\ndata_final |&gt;   \n  count(region) |&gt;  \n  arrange(desc(n))  \n\n# A tibble: 6 × 2\n  region     n\n  &lt;chr&gt;  &lt;int&gt;\n1 SSA       49\n2 AME       32\n3 AP        32\n4 WE/EU     31\n5 ECA       19\n6 MENA      18\n\n\n\n\n\n\n\n\nNota\n\n\n\nEn la última línea de código, indicamos a R que ordene los datos de acuerdo a la variable ‘n’, la cual fue definida en la línea de código precedente. Es importante recordar que la ejecución de acciones o funciones en R se realiza de manera secuencial y acumulativa.\n\n\n\n\n2.5.3 Renombrar con rename()\nPermite cambiar los nombres de las columnas de un dataframe. Para ello, se especifica el nuevo nombre deseado y el nombre actual de la columna. Esta función es útil cuando se necesita ajustar o estandarizar los nombres de las columnas en un conjunto de datos, facilitando así análisis posteriores y asegurando la claridad y consistencia en la manipulación de los datos.\nPrimero debes escribir el nuevo nombre y luego el nombre original de la variable.\n\ndata_final |&gt;   \n  rename(zona=region)   # Renombro la columna \"region\" (nombre original) como \"zona\" (nombre nuevo)\n\n# A tibble: 181 × 5\n   country      year zona  cpi_score cpi_score2\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Denmark      2022 WE/EU        90         10\n 2 Finland      2022 WE/EU        87         13\n 3 New Zealand  2022 AP           87         13\n 4 Norway       2022 WE/EU        84         16\n 5 Singapore    2022 AP           83         17\n 6 Sweden       2022 WE/EU        83         17\n 7 Switzerland  2022 WE/EU        82         18\n 8 Netherlands  2022 WE/EU        80         20\n 9 Germany      2022 WE/EU        79         21\n10 Ireland      2022 WE/EU        77         23\n# ℹ 171 more rows\n\n\n\n\n2.5.4 Recodificar con case_when()\nLa función case_when() del paquete tidyverse en R sirve para recodificar datos y crear nuevas variables o modificar variables existentes basándose en múltiples condiciones.\nPermite evaluar varias condiciones utilizando una sintaxis similar a una instrucción “if-else”. Esta función es particularmente útil cuando necesitamos recodificar una variable en varias categorías o cuando tenemos múltiples condiciones a evaluar.\nSe coloca primero la condición (fórmula) seguido del símbolo ~ (alt+126) y la etiqueta.\nAl final se coloca TRUE, lo que indica todos aquellos casos que no cumplen con las condiciones anteriores.\n\n\nsummary(data_final$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  10.00   45.00   60.50   57.02   70.25   88.00       1 \n\n\n\ndata_final&lt;-data_final |&gt; \n            drop_na(cpi_score2)\n            summary(data_final$cpi_score2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  10.00   45.00   60.50   57.02   70.25   88.00 \n\n\nPodemos realizar:\n\ndata_final&lt;-data_final  |&gt;   \n  mutate(corrupcion=case_when(cpi_score2&lt;30~\"Bajo\", \n                              cpi_score2&lt;60~\"Medio\", \n                              cpi_score2&lt;=100~\"Alto\")) \n\nLe asignamos la configuración adecuada:\n\ndata_final$corrupcion&lt;-factor(data_final$corrupcion,\n                          levels = c(\"Bajo\", \"Medio\", \"Alto\"),\n                          ordered = TRUE)\n\nFinalmente, ya contamos una nueva nueva variable ordinal creada a partir de una variable numérica:\n\nstr(data_final$corrupcion)\n\n Ord.factor w/ 3 levels \"Bajo\"&lt;\"Medio\"&lt;..: 1 1 1 1 1 1 1 1 1 1 ...",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "s2_manipulacion.html#ficha-resumen-cheat-sheet",
    "href": "s2_manipulacion.html#ficha-resumen-cheat-sheet",
    "title": "2  Manipulación de tablas",
    "section": "2.6 Ficha resumen (Cheat Sheet)",
    "text": "2.6 Ficha resumen (Cheat Sheet)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Manipulación de tablas</span>"
    ]
  },
  {
    "objectID": "index.html#trabajo-grupal",
    "href": "index.html#trabajo-grupal",
    "title": "Estadística para el Análisis Político 1",
    "section": "Trabajo grupal",
    "text": "Trabajo grupal\n\nIndicaciones\n\n\n\nLugares ricos en datos\nAquí te dejo algunas recomendaciones sobre lugares ricos en datos donde podrás encontrar datasets de insumo para construir tu base de datos.",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "index.html#sobre-el-r-y-r-studio",
    "href": "index.html#sobre-el-r-y-r-studio",
    "title": "Estadística para el Análisis Político 1",
    "section": "Sobre el R y R Studio",
    "text": "Sobre el R y R Studio\nTanto en las sesiones teóricas, como en las prácticas, se hará uso del software libre R y de la interfase Rstudio. Se requiere descargar las últimas versiones de ambos programas informáticos.\nLa última versión de R (4.3.3) puede ser descargada gratuitamente para Windows o macOS.\nhttps://cran.r-project.org/bin/windows/base/\nhttps://cran.r-project.org/bin/macosx/\nLa última versión de Rstudio Desktop (versión RStudio 2023.12.1+402) puede ser descargada aquí para Windows o macOS.\nhttps://posit.co/download/rstudio-desktop/",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "index.html#sobre-el-trabajo-grupal",
    "href": "index.html#sobre-el-trabajo-grupal",
    "title": "Estadística para el Análisis Político 1",
    "section": "Sobre el trabajo grupal",
    "text": "Sobre el trabajo grupal\n\nIndicaciones\n\n\n\nLugares ricos en datos\nAquí te dejo algunas recomendaciones sobre lugares ricos en datos donde podrás encontrar datasets de insumo para construir tu base de datos.",
    "crumbs": [
      "Sobre el curso"
    ]
  },
  {
    "objectID": "s4_introInferencia.html",
    "href": "s4_introInferencia.html",
    "title": "4  Introducción a la Inferencia",
    "section": "",
    "text": "4.1 Objetivos de la sesión",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Inferencia</span>"
    ]
  },
  {
    "objectID": "s4_introInferencia.html#objetivos-de-la-sesión",
    "href": "s4_introInferencia.html#objetivos-de-la-sesión",
    "title": "4  Introducción a la Inferencia",
    "section": "",
    "text": "Para el final de la sesión, el alumno comprenderá los fundamentos de la estadística inferencial. Asimismo, podrá calcular los intervalos de confianza de una media poblacional a partir del análisis de una muestra.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Inferencia</span>"
    ]
  },
  {
    "objectID": "s4_introInferencia.html#presentación",
    "href": "s4_introInferencia.html#presentación",
    "title": "4  Introducción a la Inferencia",
    "section": "4.2 Presentación",
    "text": "4.2 Presentación",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Inferencia</span>"
    ]
  },
  {
    "objectID": "s4_introInferencia.html#fundamentos",
    "href": "s4_introInferencia.html#fundamentos",
    "title": "4  Introducción a la Inferencia",
    "section": "4.4 Fundamentos",
    "text": "4.4 Fundamentos\n\n4.4.1 Términos básicos\n\nLa estadística inferencial utiliza la muestra de datos para hacer estimaciones y tomar decisiones acerca de las características de una población. Esto implica la utilización de técnicas y métodos para inferir información sobre la población a partir de la información recopilada en la muestra.\nAlgunas definiciones básicas:\n\n\n\n\n\n\n\nDefinición\nDescripción\n\n\n\n\nPoblación\nSe refiere al conjunto total de individuos, objetos, eventos, medidas o cualquier otra cosa que se quiera estudiar. En estadística inferencial, la población se utiliza como el objeto de estudio, y se busca inferir información sobre ella a partir de la muestra.\n\n\nMuestra\nEs un subconjunto de la población que se utiliza para hacer inferencias sobre la población en su conjunto. La selección de la muestra debe hacerse de tal forma que represente de manera adecuada las características de la población.\n\n\nEstadístico\nEs una medida numérica que se utiliza para resumir o describir alguna característica de la muestra. Los estadísticos se calculan a partir de los datos de la muestra y se utilizan para hacer inferencias sobre los parámetros de la población.\n\n\nParámetro\nEs una medida numérica que describe alguna característica de la población. En estadística inferencial, el objetivo es hacer inferencias sobre los parámetros de la población a partir de los datos de la muestra.\n\n\n\n\n\n4.4.2 Distribución normal\n\nAnteriormente te comenté que la curva normal (forma de campana) ejercía un rol fundamental en el contexto de la estadística inferencial. Esto es gracias a una propiedades muy interesantes.\nLa principal: la totalidad de observaciones están distribuidas +- 3 desviaciones estándar (puntuaciones Z) respecto de su media.\nComo se ve en la figura, son 4 los principios: 1) 50% de las puntuaciones caen encima de la media y 50% debajo; 2) Prácticamente todas las puntuaciones caen dentro de 3 SD a partir de la media en ambas direcciones (en realidad el 99.7%); 3) Cerca del 95% de las puntuaciones de una variable normalmente distribuida caen dentro de una distancia de +- 2 SD respecto de la media; y 4) Alrededor del 68% de las puntuaciones caen dentro de una distancia de +-1 SD respecto de la media.\n\n\n4.4.3 Teorema del límite central\nEl teorema del límite central (TLC) es uno de los conceptos más importantes de la estadística y es fundamental en el muestreo y la inferencia estadística.\nEn términos simples, el teorema del límite central dice que si tomamos suficientes muestras aleatorias grandes de una población, la distribución de las medias de esas muestras será una distribución normal, sin importar cómo se vea la distribución original de la población.\nEsto es importante en el muestreo porque nos permite hacer inferencias precisas sobre una población, incluso si no conocemos su distribución. Si podemos asumir que la distribución de la población es aproximadamente normal, entonces podemos usar la distribución normal de las medias de las muestras para hacer predicciones y estimaciones precisas sobre la población.\nAdemás, el TLC nos permite calcular intervalos de confianza y realizar pruebas de hipótesis (siguiente secciòn) con mayor precisión, lo que nos permite tomar decisiones más informadas basadas en los datos muestrales. En resumen, el teorema del límite central es una herramienta clave en la inferencia estadística y nos permite hacer generalizaciones precisas sobre una población a partir de datos muestrales.\nMáquina de Galton\nEl Tablero de Galton ilustra cómo la distribución de frecuencias de los resultados de muchos eventos aleatorios independientes se acerca a una distribución normal, independientemente de la forma de la distribución original, siempre que el número de eventos sea lo suficientemente grande.\n\n\n4.4.4 Ley de los grandes números\nLa ley de los grandes números es un teorema en estadística que establece que, a medida que el tamaño de una muestra aumenta, la media muestral se acerca a la media poblacional. En otras palabras, cuando se toman muestras cada vez más grandes de una población, se espera que la media de esas muestras se acerque cada vez más a la media real de la población.\nEsta ley es importante porque permite a los investigadores obtener estimaciones precisas de los parámetros de una población a partir de una muestra relativamente pequeña. Además, esta ley también es fundamental para la teoría de la probabilidad y es utilizada en muchas áreas de la estadística y de la ciencia en general.\n\n\n4.4.5 Varias muestras\nCuando extraemos varias muestras de una población y calculamos la media para cada una de esas muestras, obtenemos una variedad de medias muestrales. Aunque cada muestra es única y puede tener su propia media, si repitiéramos este proceso de muestreo muchas veces, observaríamos que la distribución de estas medias muestrales tiende a adoptar una forma específica. Esta forma es lo que conocemos como la “distribución de muestreo de la media”.\nEl Teorema del Límite Central, uno de los pilares fundamentales de la estadística inferencial, nos dice que, independientemente de la forma de la distribución original de la población, la distribución de las medias muestrales se aproximará a una distribución normal (o gaussiana) a medida que el tamaño de la muestra aumenta. Esta distribución normal centrada en la media verdadera de la población y con una desviación estándar llamada “error estándar” nos permite hacer inferencias sobre la media poblacional a partir de las medias de nuestras muestras, especialmente cuando el tamaño de la muestra es grande.\n\n\n4.4.6 Error estándar\nEl error estándar es una medida que nos indica cuánto esperamos que varíe una estadística (como la media o la proporción) de una muestra a otra, si tomáramos múltiples muestras de la misma población. En otras palabras, es una forma de medir la variabilidad que se espera en nuestras estimaciones debido al hecho de que estamos trabajando con muestras y no con la totalidad de la población.\nPodríamos pensar en el error estándar como una herramienta que nos ayuda a entender cuán “confiables” o “precisas” son nuestras estimaciones basadas en muestras. Un error estándar pequeño sugiere que nuestras estimaciones son relativamente estables y consistentes de una muestra a otra, mientras que un error estándar grande indica que esas estimaciones podrían variar considerablemente entre diferentes muestras.\nEs importante destacar que el error estándar está relacionado con la desviación estándar de la población. Mientras que la desviación estándar nos dice cuánto varían los valores individuales alrededor de la media en una población o muestra, el error estándar nos dice cuánto esperamos que varíen nuestras estadísticas de muestra (como la media muestral) alrededor de la verdadera estadística poblacional.\n\nRecuerdas que habíamos dicho que en la curva normal se podría evidenciar que la totalidad de las observaciones se encontraban entre -3 y +3 desviaciones estándar respecto de la media? En el caso de las distribuciones muestrales, esa desviación estándar es conocida como error estándar.\nEl error estándar mide la dispersión del error de muestreo que ocurre cuando se muestrea repetidamente una población (como lo hicimos líneas arriba).\n\n\\[s_{\\hat{x}} = \\frac{s}{\\sqrt{n}}\\]\nEntonces los puntos más importantes del EE son:\n\nEl error estándar es una medida de cuánto se espera que varíen las medias de las muestras tomadas de una población determinada. A medida que el tamaño de la muestra aumenta, el error estándar tiende a disminuir.\nEl error estándar es importante en el cálculo de los intervalos de confianza. Cuanto menor sea el error estándar, menor será la variabilidad de las medias muestrales y más preciso será el intervalo de confianza.\nEl error estándar se calcula dividiendo la desviación estándar de la población entre la raíz cuadrada del tamaño de la muestra. En la mayoría de los casos, la desviación estándar de la población no se conoce y se utiliza la desviación estándar de la muestra para estimar el error estándar.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Inferencia</span>"
    ]
  },
  {
    "objectID": "s4_introInferencia.html#métodos-de-estimación",
    "href": "s4_introInferencia.html#métodos-de-estimación",
    "title": "4  Introducción a la Inferencia",
    "section": "4.5 Métodos de estimación",
    "text": "4.5 Métodos de estimación\n\n4.5.1 Estimación puntual\nEn estadística inferencial, la estimación puntual se refiere a la técnica de utilizar los datos de una muestra para calcular un único valor, conocido como punto estimado, que es la mejor suposición o predicción del valor de un parámetro desconocido de la población.\nPor ejemplo, si queremos conocer el salario promedio de todos los trabajadores de una empresa, podríamos tomar una muestra aleatoria de trabajadores, calcular el salario promedio de esa muestra y usar ese valor como nuestra estimación puntual del salario promedio real de toda la empresa.\nEsencialmente, este valor es nuestra “mejor suposición” basada en la información que hemos recolectado. Sin embargo, aunque la estimación puntual es directa y fácil de entender, no refleja la incertidumbre o variabilidad que podría haber en esa estimación.\nEs por esta razón que, en muchas situaciones, se complementa con técnicas como la estimación por intervalo para obtener una visión más completa y matizada del parámetro que estamos tratando de estimar.\n\n\n4.5.2 Intervalo de confianza de una media\n\n\nEl intervalo de confianza es un rango de valores posibles de un parámetro expresado con un grado específico de confianza.\nSi tenemos un nivel de confianza de 95% quiere decir que si realizamos 100 veces el mismo procedimiento de muestreo y calculamos los estadísticos de interés, 95 veces nos van a salir resultados en los intervalos calculados. Si lo realizamos con un 99% de confianza, de igual manera, si realizamos 100 veces el procedimiento, 99 veces nos va a salir resultados en el intervalo resultante. Esto lo tenemos claro gracias a la explicación del rol que cumple la curva normal y sus propiedades.\n\n\nA MAYOR CONFIANZA MENOR ES LA PRECISIÓN (LOS INTERVALOS SON MÁS AMPLIOS)\n\n\nPara el cálculo de un intervalo de confianza utilizamos la siguiente fórmula. Recuerda\n\n\n\nEse valor que se suma y se resta a la media muestral es el término de error, sin embargo, es más conocido como margen de error.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Inferencia</span>"
    ]
  },
  {
    "objectID": "s4_introInferencia.html#ejercicio-1-enades-2022",
    "href": "s4_introInferencia.html#ejercicio-1-enades-2022",
    "title": "4  Introducción a la Inferencia",
    "section": "4.4 Ejercicio 1: ENADES 2022",
    "text": "4.4 Ejercicio 1: ENADES 2022\nEl Instituto de Estudios Peruanos, por encargo de Oxfam en Perú, elaboró la I Encuesta Nacional de percepción de Desigualdades – ENADES 2022. Este estudio pone a disposición del público el análisis estadístico más completo a la fecha sobre la percepción de las diferentes formas de desigualdad en el Perú.\nAdemás de factores económicos, la presente encuesta incluye indicadores que permiten medir la magnitud de una serie de brechas sociales y políticas: desde diferencias de género, clase y relaciones étnico-raciales, hasta dimensiones subjetivas de la desigualdad y sus vínculos con orientaciones políticas. Como se muestra a lo largo del informe, la base de datos de este proyecto provee herramientas valiosas a expertos de diferentes campos, tanto académicos como profesionales, estudiantes y personas interesadas en el análisis multidimensional de la desigualdad en el país.\nPuedes abrir el cuestionario de la encuestas aquí.\nTambién puedes ver el informe aquí.\n\n4.4.1 Abrir base de datos\n\nlibrary(haven)\nlibrary(tidyverse)\nenades&lt;-read_spss(\"data/ENADES_2022.sav\") # Con esta función abrimos archivos de SPSS\n# enades&lt;-read_spss(\"https://github.com/ChristianChiroqueR/banco_de_datos/raw/main/ENADES_2022.sav\")\n\n\nnames(enades)\n\n [1] \"NC\"          \"edad\"        \"edadr\"       \"sexo\"        \"dep\"        \n [6] \"prov\"        \"dist\"        \"zona1\"       \"zona2\"       \"zona3\"      \n[11] \"zonali1\"     \"zonali2\"     \"region\"      \"area\"        \"area2\"      \n[16] \"ambito\"      \"hijos18\"     \"hogar\"       \"edu\"         \"edur\"       \n[21] \"edu2\"        \"edupadre\"    \"edupadrer\"   \"edupadre2\"   \"edumadre\"   \n[26] \"edumadrer\"   \"edumadre2\"   \"ocup1\"       \"ocup2.CIUO1\" \"ocup2.CIUO2\"\n[31] \"ocupadre\"    \"p01.1\"       \"p01.2\"       \"p01.3\"       \"p01.4\"      \n[36] \"p01.5\"       \"p01.99\"      \"p02\"         \"p03.1\"       \"p03.2\"      \n[41] \"p03.3\"       \"p03.4\"       \"p03.5\"       \"p04\"         \"p04a\"       \n[46] \"p05\"         \"p06\"         \"p07\"         \"p07a\"        \"p08\"        \n[51] \"yhogar\"      \"yhogar_pc1\"  \"yhogar_pc2\"  \"ABq10d\"      \"p10.1\"      \n[56] \"p10.2\"       \"p10.3\"       \"p10.4\"       \"p10.5\"       \"p10.6\"      \n[61] \"p10.7\"       \"p11.1\"       \"p11.2\"       \"p11.3\"       \"p11.4\"      \n[66] \"p12.1\"       \"p12.2\"       \"p12.3\"       \"p12.4\"       \"ABros1\"     \n[71] \"ABros6\"      \"ABros4\"      \"p13\"         \"p14_1\"       \"p14_2\"      \n[76] \"p14_3\"       \"p15\"         \"p16\"         \"p17\"         \"etnicidad\"  \n[81] \"etnicidad2\"  \"ideología\"   \"ideologia2\"  \"NSE\"         \"NSE1\"       \n[86] \"NSE2\"        \"pondera\"    \n\n\n\n\n\n\n\n\nNota\n\n\n\nRecuerda que si en un primer momento te pierdes un poco entre los nombres de las variables, eso quiere decir que tienes que leer el cuestionario y el diccionario de variables!\n\n\n\n\n4.4.2 Identificar una variable numérica\nElijamos la variable P17:\n\nEn una escala del 1 al 10, en la que 1 es “Totalmente inaceptable” y 10 es “Totalmente aceptable”. ¿Hasta qué punto es aceptable la desigualdad en el Perú? Dígame un número de 1 a 10, recuerde que 1 es “Totalmente inaceptable” y 10 es “Totalmente aceptable (RESPUESTA ESPONTÁNEA)\n\nLa convertimos en numérica.\n\nenades$p17&lt;-as.numeric(enades$p17)\n\nSolicitamos los estadísticos descriptivos para darle una primera mirada.\n\nsummary(enades$p17)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  1.000   1.000   5.000   4.571   7.000  10.000      23 \n\n\nPodemos graficarlo\n\nenades |&gt; \n  ggplot() + \n  aes(x=p17)+\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n4.4.3 Cálculo del estimador puntual\nCalculamos el estimador puntual, en este caso, la media muestral.\n\nmean(enades$p17, na.rm = TRUE)\n\n[1] 4.571334\n\n\nTienes que recordar lo básico de este:\n\nEs solo una aproximación del verdadero valor poblacional, y su precisión puede variar dependiendo del tamaño y calidad de la muestra, entre otros factores.\nEs por ello que, a menudo, se complementa con intervalos de confianza para ofrecer un rango de valores en los que es probable que se encuentre el verdadero parámetro poblacional.\n\n\n\n4.4.4 Cálculo del IC al 95%\nMANUAL\nRecordemos qué necesitamos para calcular el intervalo de confianza de una media.\nNecesitamos la media muestral (mean) de esa única muestra que obtuvimos de la población, la desviación estándar (sd) y el tamaño de muestra que tenemos (n).\nAsí también, necesitamos elegir qué nivel de confianza vamos a tomar (recuerdas los intervalos de la distribución normal? y cómo se aplicaría a distribuciones muestrales?), es decir, si vamos al 95% (1.96) o algún otro nivel.\nCalculemos cada uno de estos\n\nmedia&lt;-mean(enades$p17, na.rm = TRUE)\nSE&lt;- sd(enades$p17, na.rm = TRUE)\nn &lt;-length(enades$p17)\nz&lt;- 1.96\n\nAhora recordamos la fórmula:\n\nDónde el error estándar está dado por:\n\\[s_{\\hat{x}} = \\frac{s}{\\sqrt{n}}\\]\nEntonces:\n\nerror_estandar &lt;- SE/sqrt(n)\nerror_estandar\n\n[1] 0.08009848\n\n\nPor lo pronto, hemos obtenido un error estándar con un valor de 0.08009848.\nEl error estándar, en su esencia, nos brinda una medida de cuánta variabilidad podemos esperar en nuestras estimaciones si repitiéramos el muestreo muchas veces. Cuando interpretamos un error estándar específico, como 0.08009848 podemos considerar lo siguiente:\nUn error estándar de 0.08009848 sugiere que, si tomáramos múltiples muestras del mismo tamaño de la población y calculáramos la estadística de interés (por ejemplo, la media) para cada muestra, esperaríamos que la mayoría de esas estadísticas estuvieran dentro de 0.08009848 unidades de la estadística media de todas esas muestras.\nEn otras palabras, el valor de 0.08009848 nos da una idea de la “precisión” de nuestra estimación basada en una sola muestra. Una estimación con un error estándar más pequeño generalmente se considera más “precisa” que una con un error estándar más grande, porque indica menos variabilidad entre las estimaciones de diferentes muestras.\nAhora sí, una vez calculado el error estándar podemos calcular los límite inferior o superior. Recuerda que debemos aplicar la fórmula y que la única diferencia para calcular el límite inferior y superior es el signo:\n\nlimite_inferior&lt;- media - (z*error_estandar)\nlimite_superior&lt;- media + (z*error_estandar)\n\nLos presentamos:\n\nlimite_inferior\n\n[1] 4.414341\n\nlimite_superior\n\n[1] 4.728327\n\n\nCon ello podemos concluir que: Con un 95% de confianza, podemos afirmar que la media poblacional de la aceptación de la desigualdad en el Perú (que va del 1 al 10) se encuentra entre 4.414341 y 4.728327.\nEsto lo podemos interpretar también de las siguientes forma:\n\nEstoy 95% seguro de que el promedio de aceptación de la desigualdad en el país real (es decir el parámetro) se encuentra entre 4.414341 y 4.728327.\nSi realizara este estudio 100 veces, 95 veces obtendré un promedio de aceptación de la desigualdad dentro de este intervalo: 4.414341 y 4.728327.\n\nCON LA FUNCIÓN ciMean()\nUna vez que hemos navegado por el proceso de calcular un intervalo de confianza de manera manual, utilizando la fórmula tradicional, es hora de introducir herramientas que simplifiquen y agilicen este proceso en el mundo real del análisis de datos. Para ello, en R, utilizaremos el paquete lsr y, específicamente, la función ciMean. Esta función está diseñada para calcular automáticamente el intervalo de confianza para la media de un conjunto de datos. Al proporcionarle una serie de datos como entrada, ciMean nos devuelve el rango en el que, con un nivel de confianza específico (por defecto, 95%), esperamos que se encuentre la verdadera media poblacional. Es una herramienta poderosa que combina precisión con eficiencia, permitiéndonos centrarnos en la interpretación y aplicación de nuestros resultados.\n\nlibrary(lsr)\nciMean(enades$p17, na.rm = T)\n\n         2.5%    97.5%\n[1,] 4.413023 4.729645\n\n\nEs el mismo resultado que obtuvimos arriba. Como te puedes dar cuenta, si hemos recorrido este camino (medio tedioso) es para que te quede claro cómo se obtienen esos dos números que llamamos intervalos de confianza y de qué depende en la práctica al utilizar una muestra real.\n\n\n\n4.4.5 Barras de error\nTras calcular el intervalo de confianza, una práctica recomendada es visualizarlo gráficamente. El representar este intervalo en un gráfico no solo nos facilita la comprensión de su significado, sino que también nos proporciona una perspectiva visual de dónde se sitúa nuestra estimación y el rango dentro del cual esperamos que se encuentre el verdadero valor poblacional. Al observar el intervalo de confianza en un gráfico, podemos tener una idea más intuitiva y clara de la precisión y confiabilidad de nuestra estimación, así como de la variabilidad asociada a ella.\nEn el contexto de intervalos de confianza, las barras de error se utilizan para representar el nivel de incertidumbre en una estimación puntual del parámetro poblacional. Un intervalo de confianza es un rango de valores plausible para el valor del parámetro poblacional, y se construye a partir de una muestra aleatoria y un nivel de confianza específico.\nLas barras de error en un gráfico de intervalos de confianza se construyen a partir de los límites superior e inferior del intervalo de confianza. Generalmente se dibujan líneas verticales que se extienden desde el valor estimado del parámetro (que puede ser una media, una proporción, una diferencia de medias, etc.) hasta los límites del intervalo de confianza.\nPor ejemplo, si se estima la media de una variable a partir de una muestra y se desea construir un intervalo de confianza al 95%, las barras de error se construirán a partir del límite inferior y superior del intervalo de confianza, que contendrán el verdadero valor de la media poblacional con una probabilidad del 95%.\nLas barras de error en un gráfico de intervalos de confianza pueden ser útiles para comparar la precisión de las estimaciones entre diferentes grupos o condiciones. Si las barras de error son muy pequeñas, esto sugiere que la estimación es muy precisa y que hay una alta confianza en la validez del intervalo de confianza. Por otro lado, si las barras de error son grandes, esto sugiere que la estimación es menos precisa y que hay una mayor incertidumbre en el intervalo de confianza.\nPodemos utilizar ggplot()!\n\nmediaEintervalos&lt;-enades %&gt;% \n  summarise(mean = mean(p17, na.rm = TRUE), #Utilizamos summarise y pedimos la media,\n            ci_lower = ciMean(p17, na.rm = T)[1], # También el PRIMER ELEMENTO de la función ciMean\n            ci_upper = ciMean(p17, na.rm = T)[2]) #Y el SEGUNDO ELEMENTO de la función ciMean\nmediaEintervalos\n\n# A tibble: 1 × 3\n   mean ci_lower ci_upper\n  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1  4.57     4.41     4.73\n\n\n\nmediaEintervalos %&gt;% \n  ggplot() + \n  aes(x = \"Media\", y = mean)+\n  geom_point(size = 3) + \n  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) + \n  labs(title = \"Media de aceptación de la desigualdad en el Perú (IC al 95%)\", y = \"Valor\", x = \"\")\n\n\n\n\n\n\n\n\nPuedes incluir más detalle y detallar los límites inferior y superior:\n\nmediaEintervalos %&gt;% \n  ggplot() + \n  aes(x = \"Media\", y = mean) +\n  geom_point(size = 3) + \n  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) + \n  geom_text(aes(label = round(ci_lower, 3), y = ci_lower), vjust = 1.5, hjust = -0.5) +  # Etiqueta para el límite inferior\n  geom_text(aes(label = round(ci_upper, 3), y = ci_upper), vjust = -0.5, hjust = -0.5)+  # Etiqueta para el límite superior\n  labs(title = \"Media de aceptación de la desigualdad en el Perú (IC al 95%)\", y = \"Valor\", x = \"\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Inferencia</span>"
    ]
  },
  {
    "objectID": "s4_introInferencia.html#problema",
    "href": "s4_introInferencia.html#problema",
    "title": "4  Introducción a la Inferencia",
    "section": "4.3 Problema",
    "text": "4.3 Problema\nEn esta sección, abordaremos un problema que nos permitirá explorar y comprender más a fondo los principios de la estadística inferencial. Te pido que te enfoques en mantener la esencia de esta idea a lo largo del análisis, más allá del código específico que utilizaremos.\n\n4.3.1 Población y muestra\nDada una población de 3000 individuos, el objetivo de este estudio es determinar la media de ingresos de toda la población. Debido a limitaciones de recursos, no es factible recopilar datos de todos los individuos directamente. En consecuencia, se procederá a realizar un análisis basado en una muestra representativa, con el fin de estimar la media poblacional de ingresos.\n\n\n\n\n\n\nImportante\n\n\n\nEn este punto del curso es clave que hagamos la diferencia entre población (todas las unidades de estudio que deseo estudiar y no puedo alcanzar por diversos motivos) y muestra (pequeña porción representativa de esa población).\n\n\n\nEste conjunto de datos representa nuestra población completa (denominado poblacion). Dado que no es viable calcular directamente la media de toda la población, nuestra metodología consistirá en extraer muestras. Para iniciar, procederemos con un estudio piloto extrayendo una muestra de tamaño 20.\n\nlibrary(tidyverse)\nmuestra1&lt;-poblacion |&gt; slice_sample(n=20)\nmuestra1\n\n# A tibble: 20 × 1\n   ingresos\n      &lt;dbl&gt;\n 1    1500.\n 2    1491.\n 3    1317.\n 4    1646.\n 5    1452.\n 6    1433.\n 7    1529.\n 8    1477.\n 9    1654.\n10    1337.\n11    1531.\n12    1441.\n13    1652.\n14    1250.\n15    1549.\n16    1179.\n17    1400.\n18    1735.\n19    1617.\n20    1197.\n\n\nTenemos la población y tenemos la muestra. ¿Qué sigue?\n\n\n4.3.2 Media muestral\nUna vez obtenida una muestra representativa, y con el objetivo de estimar la media de ingresos de la población total, procederemos a calcular la media de esta muestra. Este cálculo nos proporcionará una estimación aproximada de la media poblacional.\nOjo, utilizaremos datos de la muestra de 20 casos, centrados exclusivamente en la característica de ingresos.\n\nmean(muestra1$ingresos)\n\n[1] 1469.402\n\n\nA partir de los datos recopilados, hemos calculado que la media de ingresos de nuestra muestra. Esto nos permite inferir que la media de ingresos de la población total podría aproximarse a este valor.\n\n\n\n\n\n\nImportante\n\n\n\nCuando utilizamos la media de una muestra como aproximación de la media poblacional, a este proceso se le denomina estimación puntual.\n\n\n\n\n4.3.3 Varias muestras, varias medias?\nAhora bien,¿qué ocurriría si replicáramos este proceso en un universo paralelo? Procedamos a simular de nuevo la extracción de una muestra y el cálculo de la media muestral.\n¿Qué conclusiones podemos extraer de esta nueva repetición?\nUtilizaremos el código para replicar dos veces la extracción de una muestra de 20 personas y calcular la media de ingresos.\n\nmuestra2&lt;-poblacion |&gt; slice_sample(n=20)\nmean(muestra2$ingresos)\n\n[1] 1578.948\n\n\n\nmuestra2&lt;-poblacion |&gt; slice_sample(n=20)\nmean(muestra2$ingresos)\n\n[1] 1482.231\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEn este punto damos cuenta que si repetimos el proceso tendremos distintas medias muestrales. Por lo que contar con estimadores puntuales puede resultar poco consistente.\n\n\n\n\n4.3.4 Un patrón interesante: Teorema del límite central\nImagina que el ejercicio de extraer varias muestras y calcular sus medias se repitiera numerosas veces.\nDespués, en cada repetición, almacenáramos las medias obtenidas en una tabla.\n\nresultados &lt;- generar_medias_muestrales(poblacion, 2000, 20)\n\ndim(resultados)\n\n[1] 2000    2\n\nhead(resultados,10)\n\n# A tibble: 10 × 2\n   Muestras Media_Ingresos\n      &lt;int&gt;          &lt;dbl&gt;\n 1        1          1516.\n 2        2          1450.\n 3        3          1446.\n 4        4          1431.\n 5        5          1591.\n 6        6          1485.\n 7        7          1444.\n 8        8          1529.\n 9        9          1407.\n10       10          1446.\n\n\n¿Y si graficamos las 2000 medias muestrales en un histograma qué figura vemos?\n\nresultados |&gt; \n  ggplot()+\n  aes(x=Media_Ingresos)+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nEste patrón denominado distribución normal tiene ciertas particularidades que valen la pena explorar.\n\n\n\n\n\n\n\nImportante\n\n\n\nEl teorema del límite central dice que si tomamos suficientes muestras aleatorias grandes de una población, la distribución de las medias de esas muestras será una distribución normal, sin importar cómo se vea la distribución original de la población. Esta es la base de una rama importante de la estadística denominada estadística paramétrica.\n\n\n\n\n\n\n4.3.5 Distribución normal\nQue una variable posea distribución normal nos permite predecir las proporciones de casos que se encuentran en ciertos rangos, partiendo de la media.\n\nLa principal: cerca de la totalidad de observaciones están distribuidas +- 3 desviaciones estándar (puntuaciones Z) respecto de su media.\nComo se ve en la figura, son 4 los principios:\n\n50% de las puntuaciones caen encima de la media y 50% debajo;\nPrácticamente todas las puntuaciones caen dentro de 3 SD a partir de la media en ambas direcciones (en realidad el 99.7%);\nCerca del 95% de las puntuaciones de una variable normalmente distribuida caen dentro de una distancia de +- 2 SD respecto de la media; y\nAlrededor del 68% de las puntuaciones caen dentro de una distancia de +-1 SD respecto de la media.\n\n\nAhora bien, si aplicamos este principio a la distribución de medias muestrales, esto varía ligeramente.\nAquí afirmamos que el 95% de esas medias muestrales que hemos obtenido se ubicarían en el rango que consta de media - 1.96 errores estándar y media + 1.96 errores estándar. Asimismo, podemos calcular el rango en el que se encontraría el 99% (2.58) y el 90% (1.65).\nEstos números, que se utilizan para multiplicar el error estándar, son conocidos como valores críticos.\n\n\n\n\n\n\nImportante\n\n\n\nComo podrás ver, cuando hablamos de distribución de medias muestrales usamos el término error estándar, en lugar de desviación estándar. Básicamente es una medida particular para ver dispersión de esas medias. \\[s_{\\hat{x}} = \\frac{s}{\\sqrt{n}}\\]\n\n\n\n\n4.3.6 Un intervalo que contiene la media poblacional\n\nSiguiendo este principio (TLC) sumado a lo predecible que es la distribución de una variable que sigue una distribución normal, podemos aplicar lo visto en nuestra primera muestra.\nPrimero recordamos cual era nuestra media:\n\nmedia&lt;-mean(muestra1$ingresos)\nmedia\n\n[1] 1469.402\n\n\nLuego, calculamos el error estándar que es igual a la desviación estándar de la muestra sobre la raiz cuadrada del tamaño de la muestra (en nuestro caso 20).\n\nerror_estandar &lt;- sd(muestra1$ingresos)/sqrt(20)\nerror_estandar\n\n[1] 34.81994\n\n\nEntonces calculamos el intervalo utilizando la media, el valor crítico elegido (en este caso a 95%) y el error estándar.\n\nlimite_inferior&lt;- media-(1.96*error_estandar)\nlimite_superior&lt;- media+(1.96*error_estandar)\nlimite_inferior\n\n[1] 1401.155\n\nlimite_superior\n\n[1] 1537.649\n\n\nUn intervalo de confianza del 95% de 1461.839 a 1652.366 para la media deingresos indica que, si repetimos el experimento muchas veces, en el 95% de los casos, la media real de la población estará dentro de este rango.\nEn términos simples, estamos bastante seguros (con un 95% de confianza) de que la media verdadera de la población se encuentra entre 1461.839 y 1652.366.\n\n\n4.3.7 Un trade-off clave: precisión vs confianza\n\nEn la inferencia estadística, el trade-off entre precisión y confianza en los intervalos de confianza refleja un equilibrio esencial: mientras mayor es el nivel de confianza deseado (por ejemplo, 95% vs 99%), más amplio será el intervalo de confianza. Esto se debe a que un intervalo más amplio cubre una mayor proporción de los posibles valores verdaderos de la población, aumentando así nuestra confianza en que el intervalo incluye la media real.\nSin embargo, este aumento en la confianza viene a costa de la precisión, ya que un intervalo más amplio ofrece menos precisión sobre dónde se ubica exactamente esa media. Por el contrario, un intervalo más estrecho proporciona una estimación más precisa de la media, pero reduce la confianza de que el intervalo efectivamente contenga la media poblacional. Por lo tanto, la elección del nivel de confianza y del tamaño del intervalo debe considerar cuidadosamente el contexto y las necesidades específicas del análisis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Introducción a la Inferencia</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html",
    "href": "s5_Inferencia.html",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "",
    "text": "5.1 Objetivos de la sesión",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html#objetivos-de-la-sesión",
    "href": "s5_Inferencia.html#objetivos-de-la-sesión",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "",
    "text": "Se realizará un breve repaso conceptual.\nPara el final de la sesión, el alumno podrá aplicar las funciones para el cálculo del intervalo de confianza de una media y realizar su comparación en grupos. Así también, podrá realizar el intervalo de confianza de una proporción.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html#recordando-el-proceso",
    "href": "s5_Inferencia.html#recordando-el-proceso",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "5.2 Recordando el proceso",
    "text": "5.2 Recordando el proceso\n\nnetflix&lt;-c(1,1,1,1,1,1,1,1,1,2,2,2,2,3,3,3,4,4,4,4,4,4,5,5,5,5,5,5,5,5)\nmean(netflix)\n\n[1] 3\n\nconteo&lt;-table(netflix)\nconteo\n\nnetflix\n1 2 3 4 5 \n9 4 3 6 8 \n\n\n\nbarplot(conteo)\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nchoose(30, 5)\n\n[1] 142506\n\n\n\n# Todas las muestras posibles de tamaño 5 de netflix\ncombinaciones &lt;- combn(netflix, 5)\ndim(combinaciones)\n\n[1]      5 142506\n\n# Todas las medias muestrales posibles\nmedias &lt;- apply(combinaciones, 2, mean)\n\n\n# Visualizamos\nhist(medias)\n\n\n\n\n\n\n\n\nObtamos por calcular un intervalo de confianza\nEstablecemos nuestros parámetros:\n\nunica_muestra &lt;- sample(netflix, 5)\nnivel&lt;-\"95 %\"\nz&lt;-1.96\nmedia&lt;-mean(unica_muestra)\ndesviacion&lt;-sd(unica_muestra)\nerror_estandar&lt;-1.96*(desviacion/sqrt(5))\n\n\nlim_inf&lt;-media-error_estandar\nlim_sup&lt;-media+error_estandar\nprint(paste(\"A un\",nivel,\"de confianza, la media poblacional se encontrará entre\", lim_inf, \" y \", lim_sup))\n\n[1] \"A un 95 % de confianza, la media poblacional se encontrará entre 2.35970003124349  y  5.24029996875651\"\n\n\nEl principio nos dice que guiarnos por el intervalo es mucho más estable que guiarnos por un estimador puntual como la media muestral.\nProbemos, calculemos varios intervalos de confianza y grafiquemos en la pizarra.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html#recapitulando",
    "href": "s5_Inferencia.html#recapitulando",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "5.2 Recapitulando",
    "text": "5.2 Recapitulando\n\n5.2.1 Población\nEn este caso tenemos una población de 30 personas y preguntamos cuántas horas a la semana ven Netflix\n\nnetflix&lt;-c(1,1,1,1,1,1,1,1,1,2,2,2,2,3,3,3,4,4,4,4,4,4,5,5,5,5,5,5,5,5)\nconteo&lt;-table(netflix)\nconteo\n\nnetflix\n1 2 3 4 5 \n9 4 3 6 8 \n\n\nLo visualizamos en un gráfico:\n\nbarplot(conteo)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nTen en cuenta que la distribución poblacional no sigue una distribución normal.\n\n\nCon esto, sabemos que la media poblacional (parámetro) es 3.\n\nmean(netflix)\n\n[1] 3\n\n\nAhora pongamos a prueba los métodos de estimación que hemos visto.\n\n\n5.2.2 Muestra\nUna parte esencial de la inferencia estadística es la obtención de una muestra representativa, ya que esta proporciona la base sobre la cual se pueden realizar estimaciones y conclusiones acerca de una población más amplia..\nVamos a seleccionar una muestra de tamaño 5. Pero cuántas muestras distintas de tamaño 5 puedo generar de una población de 30?\n\nchoose(30, 5)\n\n[1] 142506\n\n\n\n\n\n\n\n\nImportante\n\n\n\nSi es posible extraer 142,506 muestras distintas de tamaño 5 de una población de 30, imagina la cantidad de muestras diferentes de 1200 que se podrían seleccionar de una población de 33 millones como en el Perú.\n\n\n\n\n5.2.3 Estimación puntual\nLa estimación puntual es un procedimiento estadístico que utiliza los datos de una muestra para calcular un único valor, conocido como estimador puntual, que sirve como la mejor aproximación o estimación de un parámetro poblacional desconocido.\n\nmuestra &lt;- sample(netflix, 5)\nmean(muestra)\n\n[1] 2.8\n\n\nDe acuerdo, entendemos que en este caso la estimación puntual sugiere esa media como la mejor aproximación de la media poblacional. No obstante, hemos observado también que dicha estimación presenta cierta inestabilidad.\nGenera varias muestras con el siguiente código:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n5.2.4 Teorema del límite central\nEl teorema del límite central establece que si extraemos repetidamente numerosas muestras de una población y calculamos la media de cada una, la distribución de estas medias muestrales tenderá a aproximarse a una distribución normal.\nEsto en la práctica del día no lo podemos probar, pero con un ejemplo tan acotado sí.\n\n# Todas las muestras posibles de tamaño 5 de netflix\ncombinaciones &lt;- combn(netflix, 5)\ndim(combinaciones)\n\n[1]      5 142506\n\n\nCalculamos todas las medias de las 142506 muestras:\n\n# Todas las medias muestrales posibles\nmedias &lt;- apply(combinaciones, 2, mean)\n\nLuego de extraer todas las medias las graficamos y verificamos que el principio se cumple.\n\n# Visualizamos\nhist(medias)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nObserva que la mayoría de las medias muestrales se agrupan en torno a la media verdadera, que sabemos que es 3. En este contexto, la media poblacional funciona como un centro de gravedad.\n\n\n\n\n5.2.5 Estimación por intervalo\nComo una estimación puntual es inestable, y sabemos que podemos utilizar los principios del TLC y la distribución normal (que vimos la clase pasada) obtamos por calcular un intervalo de confianza.\nOjo, la estimación la aplicamos sobre una ÚNICA MUESTRA.\n\nunica_muestra &lt;- sample(netflix, 5)\nnivel&lt;-\"95 %\"\nz&lt;-1.96\nmedia&lt;-mean(unica_muestra)\ndesviacion&lt;-sd(unica_muestra)\nerror_estandar&lt;-1.96*(desviacion/sqrt(5))\n\n\n\n\n\n\n\nImportante\n\n\n\nRecuerda que el error estándar es la puntuación crítica (z) dependiendo del nivel de confianza que haya elegido multiplicado por la desviación estándar de la variable numérica de mi muestra sobre el tamaño de la muestra.\n\n\nLuego generamos los límites inferior y superior, utilizando la media muestral y el error estándar.\n\nlim_inf&lt;-media-error_estandar\nlim_sup&lt;-media+error_estandar\nprint(paste(\"A un\",nivel,\"de confianza, la media poblacional se encontrará entre\", lim_inf, \" y \", lim_sup))\n\n[1] \"A un 95 % de confianza, la media poblacional se encontrará entre 1.05713342861032  y  3.34286657138968\"\n\n\nEl principio nos dice que guiarnos por el intervalo es mucho más estable que guiarnos por un estimador puntual como la media muestral.\nProbemos, calculemos varios intervalos de confianza y grafiquemos en la pizarra. ¿Todos incluyen el parámetro poblacional (3)?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html#índice-aditivo",
    "href": "s5_Inferencia.html#índice-aditivo",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "5.3 Índice Aditivo",
    "text": "5.3 Índice Aditivo\n\nUn índice aditivo es una técnica utilizada en la investigación social y otras áreas para combinar múltiples indicadores o variables en una única medida compuesta. La idea central detrás de un índice aditivo es sumar las puntuaciones o valores de diferentes ítems para obtener un puntaje total que represente una característica o concepto más amplio que no se puede medir directamente con un solo ítem.\nSupongamos que realizas una encuesta y pides a los encuestados que evalúen su satisfacción con los servicios públicos de agua, luz y desagüe utilizando una escala Likert de 1 (muy insatisfecho) a 5 (muy satisfecho). Ahora, deseas combinar estas tres variables en un índice aditivo que mida la satisfacción general con los servicios públicos.\nPaso 1: Obten los datos\nPor ejemplo, un encuestado ha contestado: Agua: 4 Luz: 5 Desagüe: 3\nPaso 2: Creación del índice aditivo\nPara crear el índice, simplemente sumarías las puntuaciones de estas tres variables:\nÍndice de Satisfacción = Agua + Luz + Desagüe Índice de Satisfacción = 4 + 5 + 3 = 12\nEl puntaje total para este encuestado en el índice de satisfacción con los servicios públicos sería 12. Dado que estás utilizando una escala Likert de 1 a 5 y tres servicios, el puntaje máximo posible para el índice sería 15 (si estuvieran muy satisfechos con los tres servicios) y el mínimo sería 3 (si estuvieran muy insatisfechos con los tres servicios).\nPaso 3: Estandarización\nReescalar es el proceso de ajustar el rango de una variable para que se ajuste a una nueva escala. En el contexto de nuestro índice de satisfacción con los servicios públicos, reescalar los datos a una escala de 0 a 10 puede tener varias ventajas.\n\nPrimero, una escala de 0 a 10 es intuitivamente comprensible para la mayoría de las personas, ya que es similar a las escalas que a menudo se utilizan en educación para calificar el desempeño.\nSegundo, al tener un rango definido, facilita la interpretación y comparación de los resultados. Por ejemplo, un valor de 8 en esta escala sugiere una alta satisfacción, mientras que un valor cercano a 0 indica insatisfacción.\nFinalmente, reescalar a una escala estándar como 0 a 10 puede facilitar la comparación con otros índices o estudios que utilicen la misma escala, permitiendo una evaluación más uniforme y coherente.\n\nPara ello, podemos utilizar el paquete scales y específicamente la función `rescale()``\nPaso 4: Describir\nUna vez reescalado, el índice se convierte en un resumen efectivo de las variables originales, consolidando la información en una única medida. Esta representación condensada facilita su uso en análisis posteriores. Por ejemplo, podemos obtener intervalos de confianza para el índice, proporcionando un rango de valores en el que es probable que se encuentre la verdadera media poblacional. Además, el índice reescalado puede ser utilizado en diversos modelos estadísticos, análisis de tendencias o incluso comparaciones entre diferentes grupos o períodos de tiempo, ofreciendo una herramienta versátil para la investigación y toma de decisiones.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html#intervalos-de-confianza-para-grupos",
    "href": "s5_Inferencia.html#intervalos-de-confianza-para-grupos",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "5.4 Intervalos de confianza para grupos",
    "text": "5.4 Intervalos de confianza para grupos\n\nEl intervalo de confianza de una media en grupos brinda un rango estimado para la verdadera media poblacional dentro de categorías específicas o subconjuntos de datos, siendo crucial en análisis sociopolíticos.\nEn lugar de un solo intervalo para toda una población, se calcula un intervalo para cada grupo de interés político o social.\nPermite realizar comparaciones detalladas entre distintos grupos sociopolíticos o demográficos.\nSu utilidad en ciencia política y ciencias sociales incluye: Evaluación de la aprobación de líderes políticos entre diferentes grupos demográficos (por ejemplo, por edad, género o nivel educativo), análisis de tendencias electorales en diferentes regiones o entre distintos grupos socioeconómicos, estudio de la percepción pública sobre políticas específicas, como reformas educativas o de salud, entre diferentes sectores de la población, comparación de niveles de confianza en instituciones gubernamentales entre urbanos y rurales o entre diferentes grupos étnicos, entre otros.\nEs esencial para entender las dinámicas y divisiones dentro de una sociedad, identificando posibles brechas o áreas de consenso.\n\nEn resumen, es una herramienta vital para académicos, analistas y tomadores de decisiones en ciencia política, permitiendo un análisis más profundo y matizado de las actitudes y percepciones públicas.\nPara nuestros fines, nos alejaremos un poco de la fórmula que vimos la clase pasada y lo haremos todo mucho más rápido con la utilización de la función ciMean().",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html#ejercicio-1-ic-de-la-media-de-un-índice-aditivo",
    "href": "s5_Inferencia.html#ejercicio-1-ic-de-la-media-de-un-índice-aditivo",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "5.5 Ejercicio 1: IC de la media de un índice aditivo",
    "text": "5.5 Ejercicio 1: IC de la media de un índice aditivo\n\n5.5.1 Pregunta de investigación\nEn base a la data ENADES, calcule un índice aditivo de Percepción sobre la desigualdad en el acceso a servicios públicos.\nPara ello, vamos a utilizar estas cuatro variables:\n\nBrinde el intervalo de confianza de la media de percepción sobre la desigualdad en el acceso a servicios públicos en la población al 95%\nAsimismo, genere una comparación de los intervalos de confianza para los sectores de “Lima Metropolitana” y “Perú sin Lima” (según variable zona3)\nABRIMOS LA DATA\n\nlibrary(haven)\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lsr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nenades&lt;-read_spss(\"https://github.com/ChristianChiroqueR/banco_de_datos/raw/main/ENADES_2022.sav\")\n\n\n\n5.5.2 Creamos el índice aditivo\nPaso 1: Verificar que las variables corresponden al concepto\nEn este caso las tres se destinan a medir una percepción en relación a la desigualdad de la entrega de un servicio por parte del Estado.\nPaso 2: Revisar el sentido de las categorías en el cuestionario/diccionario\nAntes de sumar las variables individuales para crear un índice aditivo, es esencial verificar la estructura y la coherencia de las categorías en las escalas de las variables que se combinarán. Las categorías de cada escala deben alinearse de manera que el progreso a través de las categorías refleje una progresión lógica y uniforme en la variable subyacente.\nPor ejemplo, si estamos evaluando la satisfacción con ciertos servicios, las categorías de la escala deberían estructurarse de manera que un número más alto indique una mayor satisfacción, mientras que un número más bajo denota menos satisfacción. Esto asegura que el índice sea intuitivo: a medida que el valor del índice aumenta, también lo hace la intensidad o el grado de la característica que se está midiendo.\nAl garantizar que las categorías de la escala estén bien alineadas y sean intuitivas, nos aseguramos de que el índice aditivo resultante sea válido y refleje de manera precisa el constructo que intentamos medir.\nEn este caso vemos que las variables tienen las siguientes escalas: (1) Muy desigual, (2) Poco desigual y (3) Nada desigual. Ciertamente, sería más intuitivo si el 3 indicaría “mucha desigualdad” y el 1 “poca desigualdad”\n\n#Percepción de desigualdad en el acceso a la educación\n#summary(enades$p11.1)\ntable(enades$p11.1)\n\n\n  1   2   3 \n912 503  80 \n\n#Percepción de desigualdad en el acceso a la salud\n#summary(enades$p11.2)\ntable(enades$p11.2)\n\n\n   1    2    3 \n1080  361   56 \n\n#Percepción de desigualdad en el acceso al trabajo\n#summary(enades$p11.3)\ntable(enades$p11.3)\n\n\n  1   2   3 \n885 544  56 \n\n#Percepción de desigualdad el acceso a la justicia\n#summary(enades$p11.4)\ntable(enades$p11.4)\n\n\n   1    2    3 \n1274  170   48 \n\n\nEn el mundo de la investigación y el análisis de datos, la exploración descriptiva inicial es una etapa crucial que no debe pasarse por alto. Esta exploración nos permite comprender la estructura, la distribución y las características generales de nuestros datos antes de realizar análisis más complejos. Una de las razones más importantes para llevar a cabo esta fase exploratoria es la detección de valores atípicos o inusuales, incluidos los valores codificados como “No sabe/No responde” (NS/NR), que a menudo se representan con códigos numéricos específicos como 999, 888, entre otros.\nCuando no se detectan o se manejan adecuadamente, estos valores codificados como NS/NR pueden introducir errores significativos en nuestros análisis. Por ejemplo, si se incluyen en el cálculo de una media, estos valores altos (como 999) inflarán artificialmente la media, resultando en una representación imprecisa de la tendencia central de los datos. Además, estos valores pueden distorsionar otros cálculos y estadísticas descriptivas, como la mediana, la varianza, y el rango.\nEn el contexto de ciencias sociales y ciencia política, donde las encuestas y los cuestionarios son herramientas comunes, los valores de NS/NR son habituales. Los encuestados pueden no querer, o no saber, cómo responder a ciertas preguntas. Es esencial identificar y manejar adecuadamente estos valores para garantizar que los resultados del análisis sean válidos y representativos de la población en estudio. Por lo tanto, una exploración descriptiva cuidadosa es el primer paso crucial para garantizar la integridad y precisión de cualquier análisis posterior.\nComo corroboramos que no hay problema de este tipo vamos a recodificar las variables para volverlas intuitivas.\n\nenades&lt;-enades |&gt; \n  mutate(p11.1n=case_when(p11.1==1~3,\n                          p11.1==2~2,\n                          p11.1==3~1,\n                          TRUE~NA_real_),\n         p11.2n=case_when(p11.2==1~ 3,\n                          p11.2==2~2,\n                          p11.2==3~1,\n                          TRUE~NA_real_),\n         p11.3n=case_when(p11.3==1~ 3,\n                          p11.3==2~2,\n                          p11.3==3~1,\n                          TRUE~NA_real_),\n         p11.4n=case_when(p11.4==1~ 3,\n                          p11.4==2~2,\n                          p11.4==3~1,\n                          TRUE~NA_real_))\n\n\ntable(enades$p11.1n)\n\n\n  1   2   3 \n 80 503 912 \n\ntable(enades$p11.2n)\n\n\n   1    2    3 \n  56  361 1080 \n\ntable(enades$p11.3n)\n\n\n  1   2   3 \n 56 544 885 \n\ntable(enades$p11.4n)\n\n\n   1    2    3 \n  48  170 1274 \n\n\nPaso 3: Creación del índice aditivo (sumar)\nAhora sí podremos realizar el índice aditivo.\n\nenades&lt;-enades |&gt; \n  mutate(indice_aditivo=p11.1n+p11.2n+p11.3n+p11.4n) #Creamos una nueva variable que es la suma de las originarias recodificadas. \n\n\nenades |&gt; \n  count(indice_aditivo)\n\n# A tibble: 10 × 2\n   indice_aditivo     n\n            &lt;dbl&gt; &lt;int&gt;\n 1              4     5\n 2              5     3\n 3              6    15\n 4              7    35\n 5              8    82\n 6              9   145\n 7             10   274\n 8             11   337\n 9             12   550\n10             NA    84\n\n\nComo nuestras variables de insumo tenían como valores posibles 1-3, nuestro índice tendrá una escala posible de 4 (si la persona contestó a todo con 1) a 12 (si la persona contestó a todo con 3).\nPaso 4: Estandarización\nSobre este índice ya creado, podemos cambiarle la escala para que no sea de 4-12 sino de 0-10.\n4A. Esto lo podemos realizar manualmente: 1) Identificamos el valor mínimo y máximo con summary(); 2) Restar a todos los valores el mínimo; 3) Al resultado, dividir por el máximo menos el mínimo; 4) Multiplicar por el número que será el nuevo máximo. Ejemplo:\n\nenades %&gt;% \n  mutate(indice_1_10=(indice_aditivo-4)/8*10) %&gt;% # \n  count(indice_1_10)\n\n# A tibble: 10 × 2\n   indice_1_10     n\n         &lt;dbl&gt; &lt;int&gt;\n 1        0        5\n 2        1.25     3\n 3        2.5     15\n 4        3.75    35\n 5        5       82\n 6        6.25   145\n 7        7.5    274\n 8        8.75   337\n 9       10      550\n10       NA       84\n\n\n4b. O también con una función (bastante más rápido)\n\nlibrary(scales)\nenades$indice_aditivo_reescalado&lt;-rescale(enades$indice_aditivo, to=c(0,10)) #Aquí mencionas que quieresque la nueva escala sea de 0 al 10. \n\nVemos que el resultado es exactamente el mismo.\n\nenades |&gt; \n  count(indice_aditivo_reescalado)\n\n# A tibble: 10 × 2\n   indice_aditivo_reescalado     n\n                       &lt;dbl&gt; &lt;int&gt;\n 1                      0        5\n 2                      1.25     3\n 3                      2.5     15\n 4                      3.75    35\n 5                      5       82\n 6                      6.25   145\n 7                      7.5    274\n 8                      8.75   337\n 9                     10      550\n10                     NA       84\n\n\n\nenades %&gt;% \n  ggplot() +\n  aes(x=indice_aditivo_reescalado)+\n  geom_bar()+\n  geom_text(stat='count', aes(label=..count..), vjust=-0.5)\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\nWarning: Removed 84 rows containing non-finite values (`stat_count()`).\nRemoved 84 rows containing non-finite values (`stat_count()`).\n\n\n\n\n\n\n\n\n\n\n\n5.5.3 Cálculo del intervalo de confianza al 95%\nEstimación puntual\nEl estimador puntual es una estadística descriptiva que se utiliza para estimar el valor desconocido de un parámetro poblacional a partir de una muestra. El estimador puntual proporciona una única estimación del valor del parámetro y se calcula a partir de los datos de la muestra.\nEn este caso, la mejor estimación de la media población es simplemente la media muestral.\n\nmean(enades$indice_aditivo_reescalado, na.rm=TRUE) #Calculamos la media, obviando valores perdidos. \n\n[1] 8.293568\n\n\n\n\n5.5.4 IC para una media\nAhora, una vez identificado el estimador puntual, podemos cambiar nuestra estimación, ahora utilizando intervalos.\nLa clase pasada lo hicimos con la fórmula, paso por paso. Ahora, utilizaremos una función:\n\n#library(lsr) #Recuerda que esta función está en el paquete lsr\nciMean(enades$indice_aditivo_reescalado, na.rm = T) # Calculamos el intervalo de confianza de p17, obviando valores perdidos. \n\n         2.5%    97.5%\n[1,] 8.197055 8.390082\n\n\n\n\n5.5.5 IC para una media según grupos\nUna vez que ya tenemos nuestra variable numérica, lo que necesitamos para comparar es justamente un grupo de comparación. Ya hablando en programación del R, necesitamos un factor.\nRecuerda que el factor era una variable que visualmente son números, pero teóricamente sabemos que cada número es un nivel.\nUtilizaremos la variable zona3, la cual separa a los encuestados según su procedencia en: “Lima Metropolitana” y “Perú sin Lima”.\nVeamos:\n\nenades$zona3&lt;-factor(enades$zona3, # Nombre de la variable a convertir\n                     levels=1:2, # Definimos los niveles (esta variable sólo tenía 2 niveles)\n                     labels=c(\"Lima Metropolitana\", \"Perú sin Lima\")) #Colocamos sus etiquetas\n\n#Con este comando hemos sobreescrito la variable zona3. Ahora lo que inicialmente era una variable numérica, ahora es un factor. \n\nCorroboremos:\n\nstr(enades$zona3) #Solicitamos la estructura de la variable zona3\n\n Factor w/ 2 levels \"Lima Metropolitana\",..: 1 1 2 2 2 2 2 2 2 2 ...\n\n\nSolicitemos el intervalo de confianza de la variable creada para cada grupo identificado:\n\nindice_segun_zona&lt;-enades %&gt;% \n  group_by(zona3) %&gt;% #Agrupamos por zona\n  summarise(mean = mean(indice_aditivo_reescalado, na.rm = TRUE), #Utilizamos summarise y pedimos la media,\n            ci_lower = ciMean(indice_aditivo_reescalado, na.rm = T)[1], # También el PRIMER ELEMENTO de la función ciMean\n            ci_upper = ciMean(indice_aditivo_reescalado, na.rm = T)[2]) #Y el SEGUNDO ELEMENTO de la función ciMean\n\n\nindice_segun_zona\n\n# A tibble: 2 × 4\n  zona3               mean ci_lower ci_upper\n  &lt;fct&gt;              &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Lima Metropolitana  8.48     8.33     8.64\n2 Perú sin Lima       8.19     8.07     8.31\n\n\nSegún el cálculo, para Lima Metropolitana la media poblacional se encuentra entre 8.49 y 8.77, mientras que para Perú sin Lima se encuentra entre 8.25 y 8.47.\nINTERPRETACIÓN\nAl comparar dos intervalos de confianza entre grupos, lo más importante a tener en cuenta son:\n\nSuperposición de Intervalos: Si los intervalos de confianza de dos grupos no se superponen, esto sugiere una diferencia estadísticamente significativa entre las medias de los grupos en la población.\n\n-Posición del Intervalo en la Escala: Aparte de la superposición, es esencial observar dónde se sitúan los intervalos en la escala. Si un grupo tiene un intervalo de confianza que se sitúa consistentemente más alto que el otro, puede indicar una tendencia o dirección en la diferencia entre los grupos.\n\nNivel de Confianza Utilizado y amplitud el intervalo: Es importante recordar el nivel de confianza utilizado al construir los intervalos (por ejemplo, 95%). Un nivel de confianza más alto resultaría en intervalos más amplios, mientras que un nivel más bajo daría como resultado intervalos más estrechos.\n\nAplicando a los resultados precisados:\n\nSuperposición: No hay. Un intervalo va de 8.49 a 8.77 (Lima Metropolitana) y el otro de 8.25 y 8.47 (Perú sin Lima). Esto sugiere una diferencia estadísticamente significativa entre estos sectores.\nPosición del intervalo en la escala: Podemos decir que tenemos indicio de que en promedio la percepción de desigualdad en el acceso a servicios es más alta en Lima que en el resto del país.\nNivel de confianza: Recordemos, cuando usamos ciMean() estamos utilizando un nivel de confianza del 95% por default.\n\nPor ejemplo, cuánto sería los intervalos de confianza al 99%?\n\nenades %&gt;% \n  group_by(zona3) %&gt;% \n  summarise(mean = mean(indice_aditivo_reescalado, na.rm = TRUE),\n            ci_lower = ciMean(indice_aditivo_reescalado, na.rm = TRUE, conf = 0.99)[1], \n            ci_upper = ciMean(indice_aditivo_reescalado, na.rm = TRUE, conf = 0.99)[2])\n\n# A tibble: 2 × 4\n  zona3               mean ci_lower ci_upper\n  &lt;fct&gt;              &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Lima Metropolitana  8.48     8.28     8.69\n2 Perú sin Lima       8.19     8.03     8.35\n\n\n\nQué puedes observar?\n\n\n\n5.5.6 Visualización\nComo dijimos, las barras de error en un gráfico de intervalos de confianza pueden ser útiles para comparar la precisión de las estimaciones entre diferentes grupos o condiciones.\nPodemos utilizar un comando básico como la función plotmeans():\n\nlibrary(gplots)\nplotmeans(enades$indice_aditivo_reescalado~enades$zona3, p=0.95, \n          xlab=\"Ámbito\", ylab=\"Índice de percepción de desigualdad en acceso a servicios\", \n          main=\"Gráfico de medias de Índice Aditivo\")\n\n\n\n\n\n\n\n\nSin embargo, te recomiendo utilizar ggplot()!\n\nindice_segun_zona |&gt; #Data\n  ggplot()+       #Iniciamos el ggplot. A partir de ahora son +! ya no |&gt;!\n  aes(y=mean, x=zona3)+  #Los grupos en el eje X y la media en el eje Y\n  geom_errorbar(aes(ymin=ci_lower, ymax=ci_upper), width=0.2)+ #Graficamos la barra de error\n  geom_text(aes(label=paste(round(mean, 2))), vjust=0, size=5)+ #Colocamos el texto del valor de la media\n  xlab(\"Procedencia\") + #Etiqueta del eje X\n  ylab(\"Percepción de la desigualdad\") # Etiqueta del eje y\n\n\n\n\n\n\n\n\n\nRECUERDA: Se superponen los intervalos?\n\nSi los intervalos de confianza se superponen significa que no hay una diferencia estadísticamente significativa entre las estimaciones correspondientes a cada intervalo. Es decir, la diferencia entre las estimaciones no es lo suficientemente grande como para ser considerada significativa desde un punto de vista estadístico.\nIMPORTANTE!!\nEs importante tener en cuenta que la superposición de los intervalos de confianza no es una prueba concluyente de que no hay una diferencia significativa entre las estimaciones. Se debe realizar una prueba de hipótesis para determinar si la diferencia es estadísticamente significativa o no. Sin embargo, la superposición de los intervalos de confianza puede ser una indicación inicial de que la diferencia no es significativa y que no se debe buscar más evidencia.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html#ejercicio-2",
    "href": "s5_Inferencia.html#ejercicio-2",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "5.6 Ejercicio 2",
    "text": "5.6 Ejercicio 2\nPREGUNTA\nUtilizando la variable monto mínimo mensual que requiere su hogar para vivir (P08).\nCalcule:\n\nBrinde el estimador puntual de la media poblacional.\nCalcule el intervalo de confianza de la media poblacional.\nCalcule los intervalos de confianza de la media según si el individuo vive en el área urbana o rural (area2). En otras palabras, compare la media de la variable en esos dos grupos.\nRealice un gráfico de barras de error. Existe indicio de DIFERENCIA entre los dos grupos?\n\n\nTienes 15 minutos!",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html#intervalo-de-confianza-de-una-proporción",
    "href": "s5_Inferencia.html#intervalo-de-confianza-de-una-proporción",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "5.7 Intervalo de confianza de una proporción",
    "text": "5.7 Intervalo de confianza de una proporción\n\n5.7.1 Definición\nEn estadística, el intervalo de una proporción es un rango de valores posibles para la proporción de una característica en una población, que se estima a partir de una muestra aleatoria de la población. Al igual que con la media, el intervalo de una proporción se construye utilizando un nivel de confianza específico y se utiliza para determinar la precisión de la estimación de la proporción en la población.\nPor ejemplo, si se desea estimar la proporción de personas en una población que votará por un candidato específico, se puede seleccionar una muestra aleatoria de la población y estimar la proporción de personas que votarán por ese candidato en la muestra. A partir de esta estimación, se puede construir un intervalo de confianza que contendrá el valor real de la proporción en la población con un cierto nivel de confianza.\nEl ancho del intervalo depende del tamaño de la muestra y del nivel de confianza especificado. A medida que el tamaño de la muestra aumenta, el intervalo se estrecha y se vuelve más preciso. Del mismo modo, a medida que se aumenta el nivel de confianza, el intervalo se amplía y se vuelve menos preciso.\nEl intervalo de una proporción es una herramienta útil en la inferencia estadística, ya que permite a los investigadores cuantificar la incertidumbre en una estimación de la proporción y determinar si una diferencia entre dos proporciones es estadísticamente significativa.\n\n\n5.7.2 Fórmula\n\nRecuerda que en este caso, al igual que en la media, todo gira en torno a los principios de la curva normal, el número de desviaciones estándar/errores estándar a la izquierda y a la derecha, el teorema central del límite y la ley de los grandes números. Si alguno de estos conceptos no están claros, te recomiendo regresar a la sesión 4 y repasarlos!\n\nPara calcular el intervalo de confianza de una proporción variamos un poco la fórmula que ya conocemos hasta ahora.\nPrimero hay que tener en cuenta que cuando calculamos la proporción, nos estamos refiriendo específicamente a la proporción de UNA CATEGORÍA de una variable CATEGÓRICA. Hago el énfasis en ello porque siempre se genera la confusión de “a qué le estoy calculando la proporción”.\nDicho de otra manera, nosotros debemos poner el ojo en una categoría de una variable nominal/ordinal al principio de este cálculo.\n\\[\\text{Intervalo de confianza para una proporción: } \\hat{p} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\]\nDonde:\n\\(\\hat{p}\\) = Proporción muestral de la categoría elegida\nz = Puntuación crítica dependiendo de nuestro nivel de confianza elegido\n\\(\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\) = Error estándar de una proporción\n\n\n5.7.3 IC de proporción con la fórmula\nPrimero ubiquemos una variable categórica. Utilicemos la p11.1:\n¿Qué tan desigual es el acceso de los peruanos a la EDUCACIÓN? 1. Muy desigual 2. Poco desigual 3. Nada desigual\n\n#Configuramos nuestra variable como factor\nenades$p11.1&lt;-factor(enades$p11.1, # Nombre de la variable a convertir\n                     levels=1:3, # Definimos los niveles (esta variable sólo tenía 2 niveles)\n                     labels=c(\"Muy desigual\", \"Poco desigual\", \"Nada desigual\")) #Colocamos sus etiquetas\n\nLa muestra se divide entre estas tres opciones. Ahora elegimos UNA CATEGORÍA de estas tres a la que vamos a calcular la proporción. En este caso vamos a elegir la proporción de individuos que afirmó que el acceso a la educación en el Perú es “Muy desigual”.\n\n#Calculamos p\nenades |&gt; \n  count(p11.1) |&gt; \n  drop_na(p11.1) |&gt;\n  mutate(p=n/sum(n))\n\n# A tibble: 3 × 3\n  p11.1             n      p\n  &lt;fct&gt;         &lt;int&gt;  &lt;dbl&gt;\n1 Muy desigual    912 0.610 \n2 Poco desigual   503 0.336 \n3 Nada desigual    80 0.0535\n\n\nAhora sabemos que nuestro \\(\\hat{p}\\) = 0.59\n\np&lt;-0.61003344\n\nEl número total de casos es:\n\nn&lt;- 912+503+80\n\nAhora definimos la puntuación crítica. Cuánto era para 95% de confianza?\n\nz&lt;-1.96\n\nAhora el error estándar \\(\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\)\n\nerror_estandar&lt;- sqrt((p*(1-p))/n)\n\nNuestro límite inferior es la proporción muestral menos z*error estándar:\n\nlimite_inferior&lt;- p-z*error_estandar\nlimite_inferior\n\n[1] 0.585309\n\n\nY el límite superior es la proporción muestral más z*error estándar:\n\nlimite_superior&lt;- p+z*error_estandar\nlimite_superior\n\n[1] 0.6347579\n\n\nLo podemos colocar todo en un data frame\n\nresultados&lt;-data.frame(p, error_estandar, limite_inferior, limite_superior)\nresultados |&gt; \n  kbl() |&gt; \n  kable_styling()\n\n\n\n\np\nerror_estandar\nlimite_inferior\nlimite_superior\n\n\n\n\n0.6100334\n0.0126145\n0.585309\n0.6347579\n\n\n\n\n\n\n\n\n\n5.7.4 IC de proporción con prop.test()\nAhora bien, también podemos utilizar la función prop.test():\nRecordemos:\n\nenades |&gt; \n  count(p11.1) |&gt; \n  drop_na(p11.1) |&gt; \n  mutate(p=n/sum(n))\n\n# A tibble: 3 × 3\n  p11.1             n      p\n  &lt;fct&gt;         &lt;int&gt;  &lt;dbl&gt;\n1 Muy desigual    912 0.610 \n2 Poco desigual   503 0.336 \n3 Nada desigual    80 0.0535\n\n\nColocamos la frecuencia de la categoría elegida y el tamaño total de la muestra.\n\nprop.test(912, 1495)$conf.int\n\n[1] 0.5847202 0.6347751\nattr(,\"conf.level\")\n[1] 0.95\n\n\n\nPor qué colocamos frecuencia? Porque así está configurada esta función.\n\n\n\n5.7.5 IC de proporción según grupos\nAhora comparemos la proporción elegida (aquellos que creen que el acceso de los peruanos a la EDUCACIÓN es MUY DESIGUAL) entre el sector rural y urbano (area2).\n\nenades$area2&lt;- factor(enades$area2, # Nombre de la variable a convertir\n                     levels=1:2, # Definimos los niveles (esta variable sólo tenía 2 niveles)\n                     labels=c(\"Urbano\", \"Rural\")) #Colocamos sus etiquetas\n\nPrimero, nos tenemos que preguntar cuál es la frecuencia en cada grupo\n\nenades |&gt; \n  group_by(area2) |&gt; \n  drop_na(p11.1) |&gt;\n  count(p11.1) |&gt; \n  mutate(p=n/sum(n))\n\n# A tibble: 6 × 4\n# Groups:   area2 [2]\n  area2  p11.1             n      p\n  &lt;fct&gt;  &lt;fct&gt;         &lt;int&gt;  &lt;dbl&gt;\n1 Urbano Muy desigual    769 0.618 \n2 Urbano Poco desigual   409 0.329 \n3 Urbano Nada desigual    67 0.0538\n4 Rural  Muy desigual    143 0.572 \n5 Rural  Poco desigual    94 0.376 \n6 Rural  Nada desigual    13 0.052 \n\n\nAhora calculamos la función teniendo en cuenta que:\n\nEn el primer grupo hay 769 casos de éxito de un total de 1273.\n\nLo ingresamos a la función:\n\nprop.test(x=c(769), n=c(769+409+67))$conf.int\n\n[1] 0.5899485 0.6446582\nattr(,\"conf.level\")\n[1] 0.95\n\n\n\nEn el segundo grupo hay 143 casos de éxito de un total de 257.\n\n\nprop.test(x=c(143), n=c(143+94+13))$conf.int\n\n[1] 0.5080285 0.6337218\nattr(,\"conf.level\")\n[1] 0.95\n\n\nLo podemos ordenar en un data.frame.\n\nresultados_prop&lt;-  data.frame(Grupo =c(\"Urbano\", \"Rural\"), \n                              P =c(0.61767068, 0.57200000   ), \n                              Lim_inf=c(0.5899485, 0.5080285), \n                              Lim_sup= c(0.6446582,0.6337218))\n\n\nresultados_prop\n\n   Grupo         P   Lim_inf   Lim_sup\n1 Urbano 0.6176707 0.5899485 0.6446582\n2  Rural 0.5720000 0.5080285 0.6337218\n\n\nLo visualizamos:\n\nresultados_prop |&gt; #Data\n  ggplot()+       #Iniciamos el ggplot. A partir de ahora son +! ya no |&gt;!\n  aes(y=p, x=Grupo)+  #Los grupos en el eje X y la media en el eje Y\n  geom_errorbar(aes(ymin=Lim_inf, ymax=Lim_sup), width=0.2)+ #Graficamos la barra de error\n  xlab(\"Procedencia\") + #Etiqueta del eje X\n  ylab(\"P la cobertura en educación es Muy Desigual\") # Etiqueta del eje y\n\n\n\n\n\n\n\n\nOtra alternativa es pedirlos al mismo tiempo en la función prop.test(). En este caso lo que nos muestra, es el intervalo de la diferencia.\n\nprop.test(x=c(769, 143), n=c(1273, 257))$conf.int\n\n[1] -0.02108879  0.11641800\nattr(,\"conf.level\")\n[1] 0.95\n\n\nEn este caso, se sigue la siguiente interpretación:\nSi el intervalo de confianza no contiene el valor cero, esto sugiere que las proporciones de los dos grupos son significativamente diferentes y que la hipótesis nula de que las proporciones son iguales debe ser rechazada. Por otro lado, si el intervalo de confianza contiene el valor cero, no podemos rechazar la hipótesis nula y no podemos concluir que las proporciones son significativamente diferentes.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  },
  {
    "objectID": "s5_Inferencia.html#ejercicio-3",
    "href": "s5_Inferencia.html#ejercicio-3",
    "title": "5  Profundizando en la Estadística Inferencial",
    "section": "5.8 Ejercicio 3",
    "text": "5.8 Ejercicio 3\nPREGUNTA\nUtilizando la variable “ideología2” (1: Izquierda, 2:Centro, 3:Derecha):\nRealice lo siguiente:\n\nBrinde el estimador puntual de la proporción de población de Izquierda en el Perú.\nCalcule el intervalo de confianza de la proporción poblacional de Izquierda en el Perú.\nCalcule por separado, utilizando prop.test(), la proporción de población de izquierda en el área urbano y rural (area2).\nMediante la función prop.test(), compare los dos grupos y evalúe el intervalo de confianza de la diferencia en los p poblacionales.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Profundizando en la Estadística Inferencial</span>"
    ]
  }
]